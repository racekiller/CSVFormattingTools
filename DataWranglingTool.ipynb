{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# latest update\n",
    "# October 1st 2017\n",
    "# Changes done by: Jimmy Vivas\n",
    "# Added code description\n",
    "\n",
    "# This code was developed by Jimmy Vivas\n",
    "\n",
    "# The code will take all CSv files from a specific directory and process them at the same Time\n",
    "# The program will need manual input to replace strings found for numeric data or null value\n",
    "#   It will assign an integer value for each distinct string for each column (sensor)\n",
    "# The code will generate as many csv files pero 1MM rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 -. Update the path where the CSV file is located and hit SHIFT + ENTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create two folders\n",
    "#### Folder 1 = CSVPAath1 is where the CSV file to be processed is located\n",
    "#### Folder 2 = FinalPath is where all the files processed will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Windows Path\n",
    "CSVPath1 = '/Users/jvivas/Documents/aspen/MOTIVA/to be processed'\n",
    "FinalPath = '/Users/jvivas/Documents/aspen/MOTIVA/processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2-. Execute Next line Hitting Shift+ENTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MOTIVA_CP10452_2015_June to December.csv\n",
      "Renaming date and time column\n",
      "Applying date and time format\n",
      "Extracting strings from csv file\n",
      "Converting df to numeric\n",
      "Total columns with text: Index(['9PC4344B.PIDA.SP', '9PI0849.DACA.PV', '9PC3560.PIDA.SP',\n",
      "       '9PI0278.DACA.PV', '9TC0277.DACA.PV', '9HS3853A.PV', '9HS3853B.PV',\n",
      "       '9HS3854A.PV', '9HS3854B.PV', '9TI3886B.DACA.PV',\n",
      "       ...\n",
      "       '9ZL3876.PV', '9AI1296C.DACA.PV', '9LI3862.PV', '9ZL3877.PV',\n",
      "       '9FC3885.PIDA.SP', '9HS3883A.PV', '9HS3883B.PV', '9PC3638.PIDA.SP',\n",
      "       '9TI3884.DACA.PV', '9FC1234.DACA.PV'],\n",
      "      dtype='object', length=153)\n",
      "Sensors with text in their Values: ['9PI0849.DACA.PV', '9TC0277.DACA.PV', '9TI0441.DACA.PV', '9TI0447.DACA.PV', '9TI0448.DACA.PV', '9TI0449.DACA.PV', '9TI0453.DACA.PV', '9TI0454.DACA.PV', '9TI0431.DACA.PV', '9TI0433.DACA.PV', '9TI0436.DACA.PV', '9TI0272.DACA.PV', '9FI0455.DACA.PV', '9LI3851.DACA.PV', '9PI3863.DACA.PV', '9PC3646.DACA.PV', '9PI3864.DACA.PV', '9TI0424A.DACA.PV', '9TI0424B.DACA.PV', '9TI0425D.DACA.PV', '9TI0425E.DACA.PV', '9TI0425F.DACA.PV', '9TI0425G.DACA.PV', '9TI0425A.DACA.PV', '9TI0425B.DACA.PV', '9TI0425C.DACA.PV', '9TI0425H.DACA.PV', '9TI0451A.DACA.PV', '9TI0451B.DACA.PV', '9TI0452G.DACA.PV', '9TI0452H.DACA.PV', '9TI0452J.DACA.PV', '9TI0452K.DACA.PV', '9TI0452L.DACA.PV', '9TI0452M.DACA.PV', '9TI0452A.DACA.PV', '9TI0452B.DACA.PV', '9TI0452C.DACA.PV', '9TI0452D.DACA.PV', '9TI0452E.DACA.PV', '9TI0452F.DACA.PV', '9TI0452N.DACA.PV', '9TI0427A.DACA.PV', '9TI0427B.DACA.PV', '9TI0428D.DACA.PV', '9TI0428E.DACA.PV', '9TI0428F.DACA.PV', '9TI0428G.DACA.PV', '9TI0428A.DACA.PV', '9TI0428B.DACA.PV', '9TI0428C.DACA.PV', '9TI0428H.DACA.PV', '9TI0444A.DACA.PV', '9TI0444B.DACA.PV', '9TI0443G.DACA.PV', '9TI0443H.DACA.PV', '9TI0443J.DACA.PV', '9TI0443K.DACA.PV', '9TI0443L.DACA.PV', '9TI0443M.DACA.PV', '9TI0443A.DACA.PV', '9TI0443B.DACA.PV', '9TI0443C.DACA.PV', '9TI0443D.DACA.PV', '9TI0443E.DACA.PV', '9TI0443F.DACA.PV', '9TI0443N.DACA.PV', '9TI0510A.DACA.PV', '9TI0510B.DACA.PV', '9TI0511B.DACA.PV', '9TI0511C.DACA.PV', '9TI0511A.DACA.PV', '9TI0511D.DACA.PV', '9TI0513A.DACA.PV', '9TI0514B.DACA.PV', '9TI0514C.DACA.PV', '9TI0514A.DACA.PV', '9TI0514D.DACA.PV', '9PI3553.DACA.PV', '9TI0412.DACA.PV']\n",
      "Processing Sensor: 9TI0425G.DACA.PV\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-39941883b608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting strings from csv file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mStringListForAllSensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractStrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'These are all the strings found in the csv file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringListForAllSensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jvivas/Documents/GitHub/CSVFormattingTools/utils.py\u001b[0m in \u001b[0;36mExtractStrings\u001b[0;34m(df2_1, df2_2)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAllSensorsStringList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "CSVFileList = GetCSVList(CSVPath1)\n",
    "\n",
    "CSVFile = CSVFileList[0]\n",
    "CSVFileWithPath = CSVPath1 + \"/\" + CSVFileList[0]\n",
    "\n",
    "csvFileSizeGB = GetFileSize(CSVFileWithPath)\n",
    "\n",
    "if csvFileSizeGB > 1:\n",
    "    StringListForAllSensors = SplitCSVFile_GetStrings(CSVFileWithPath, CSVFile)\n",
    "    print ('These are all the strings found in the file: ' + str(StringListForAllSensors))\n",
    "else:\n",
    "    \n",
    "    df2 = LoadCSV(CSVFileWithPath, CSVFile)\n",
    "    \n",
    "    # Rename date and time column\n",
    "    print ('Renaming date and time column')\n",
    "    RenameColumn(df2)\n",
    "    # Apply Date and time format to dataframe\n",
    "    print ('Applying date and time format')\n",
    "    ApplyDateFormat(df2)\n",
    "    \n",
    "    # Apply Index and create two dataframes\n",
    "    df2_1, df2_2 = SetIndex(df2)\n",
    "    \n",
    "    print ('Extracting strings from csv file')\n",
    "    StringListForAllSensors = ExtractStrings(df2_1, df2_2)\n",
    "    \n",
    "    print ('These are all the strings found in the csv file: ' + str(StringListForAllSensors))\n",
    "\n",
    "# Convert all strings to a Dictionary\n",
    "StringListDict = {}.fromkeys(StringListForAllSensors, 'null')\n",
    "\n",
    "# print (\"# Run following line to see the list of Strings\")\n",
    "## Copy the result and paste it in the following line of code\")\n",
    "print(StringListDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensors with low Standard Deviation Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "\n",
    "for key,value in StringListDict.items():\n",
    "    if value not in result.values():\n",
    "        result[key] = value\n",
    "\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_2_LowStdDev = GetLowStdDevSensors(df2_2, CSVPath1)\n",
    "# print (df2_2_LowStdDev)\n",
    "# print ('Sensors Plots has been exported to:')\n",
    "# print (CSVPath1)\n",
    "# print ('Please review them and choose wich sensors will be excluded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 -. Copy the StringListDict and replace the null with the desired numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing known test to null\n",
    "df2_2 = ReplaceStrings(df2_2, StringListDict)\n",
    "\n",
    "# Create dataframe to export individual tags\n",
    "df_final = pd.concat([df2_1, df2_2])\n",
    "\n",
    "# Export Individual Tags to CSV\n",
    "print(\"Creating CSV per TagName\")\n",
    "ExportTagNamesToCSV(df_final,FinalPath)\n",
    "\n",
    "# Merge dataframes to export to CSV\n",
    "mdf = FormatToPrevise(df2_1,df2_2)\n",
    "\n",
    "# Check format data to be exportedaa\n",
    "mdf.head(25)\n",
    "\n",
    "# Export to CSV\n",
    "print ('Creating CSVs to be imported into Aspen Mtell')\n",
    "SplitPreviseFormatCSVFile(mdf,CSVFileList,FinalPath)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
