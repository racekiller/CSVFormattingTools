{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# latest update\n",
    "# April 26, 2017\n",
    "# Changes done by: Jimmy Vivas\n",
    "# Added code description\n",
    "\n",
    "# This code was developed by Jimmy Vivas\n",
    "\n",
    "# The code will take all CSv files from a specific directory and process them at the same time\n",
    "# The code will get replace strings in the values for numeric data\n",
    "#   It will assign an integer value for each distinct string for each column (sensor)\n",
    "#   The integer value will be reset it for each sensor\n",
    "#   The code does not evaluare wether or not the sensor should stay. THe analyst will make this decision\n",
    "#   Using Previse or any other tool\n",
    "# The code will split the csv file if the result is more than 1MM rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mac Path\n",
    "#CSVPath1 =  '/Users/jvivas/Documents/XMT Baytwon Sensor Data' \\\n",
    "#            '/Sensor Data/Testing'\n",
    "\n",
    "CSVPath1 = '/Users/jvivas/Documents/Aspen/PTT GC PoC/Sensor Data/A210 - Quench Oil Tower/To Be Processed'\n",
    "\n",
    "# Windows Path\n",
    "# CSVPath1 = 'C:/Users/jvivas/Dropbox/Mtell Customer Projects/XOM BayTown RHC MEA Tower Foaming/Sensor Data/' \\\n",
    "#           'To be Processed'\n",
    "\n",
    "# CSVPath1 = 'C:/Mtell/Projects/XOM Baytown POC/Sensor Data/ToBeFormatted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CSVFileList = []\n",
    "NanPHDTagList = []\n",
    "CSVFileListAll = listdir(CSVPath1)\n",
    "\n",
    "m = len(CSVFileListAll)\n",
    "\n",
    "for i in range(m):\n",
    "    fileNameStr = CSVFileListAll[i]\n",
    "    fileStr = fileNameStr.split('.')[0]\n",
    "    fileExt = fileNameStr.split('.')[1]\n",
    "    if fileExt == \"csv\":\n",
    "        CSVFileList.append(fileNameStr)\n",
    "\n",
    "n = len(CSVFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncomment following cell for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Segment: A210_3Columns_Small.csv\n",
      "Time Loading A210_3Columns_Small.csv file\n",
      "CPU times: user 1.58 ms, sys: 383 µs, total: 1.97 ms\n",
      "Wall time: 1.78 ms\n",
      "2 columns contain strings out of 3 columns\n",
      "this process will take some time depending of the size of the file and the PC resources\n",
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n",
      "Processing Sensor: tagname 1\n",
      "{'tagname 1': ['test', 'hello there'], 'tagname 2': []}\n",
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.96 µs\n",
      "Processing Sensor: tagname 2\n",
      "{'tagname 1': ['test', 'hello there'], 'tagname 2': ['wow more text']}\n",
      "{'tagname 1': ['test', 'hello there'], 'tagname 2': ['wow more text']}\n",
      "['wow more text', 'test', 'hello there']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(n):\n",
    "    csvfile = CSVPath1 + \"/\" + CSVFileList[i]\n",
    "    print(\"Loading Segment: %s\" % CSVFileList[i])\n",
    "\n",
    "    # In[43]:\n",
    "    print ('Time Loading ' + CSVFileList[i] + ' file')\n",
    "    %time df = pd.read_csv(csvfile, index_col=False, sep=',', low_memory=False)\n",
    "    \n",
    "    # In[51]:\n",
    "    # Need to do this to avoid \n",
    "    df = df.copy()\n",
    "    # Change new datetime column to datetime format\n",
    "    df['Date TIme'] = pd.to_datetime(df['Date TIme'])\n",
    "    # In[53]:\n",
    "    # Change datetime column format to look like 01/31/2015 0:00:00\n",
    "    df['Date TIme'] = df['Date TIme'].dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "    # Code to do Transposing\n",
    "    # Create two dataframes df1 only with tags and descriptions. df2 tag with values\n",
    "    df1 = df[0:1]  # FIRST ROW\n",
    "    df2 = df[1:len(df)]  # SECOND TO LAST ROW\n",
    "    \n",
    "    # Indexing dataframe df1\n",
    "    df1 = df1.set_index('Date TIme')\n",
    "\n",
    "    # Indexing dataframe df2\n",
    "    df2 = df2.set_index('Date TIme')\n",
    "\n",
    "    # Convert columns to numbers those that has string wil be converted to numpy null = NaN\n",
    "    df2_with_nan = df2.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "    # Ge the list of sensors with Strings\n",
    "    df3 = pd.DataFrame(df2_with_nan.isnull().any(axis=0))\n",
    "    df3 = df3.reset_index()\n",
    "    SensorsWithStrings = df3[df3[0]==True]['index'].tolist()\n",
    "    \n",
    "    # Replace nan with 'null' and create new df\n",
    "    df2_with_null = df2_with_nan.fillna(value='null')\n",
    "    \n",
    "    # Here we filter the columns that are objects and create a dataframe with those columns\n",
    "    colsObject = df2.select_dtypes(include=['object']).columns\n",
    "    TotalColumns = df2.columns\n",
    "    \n",
    "    # print status\n",
    "    print (str(len(SensorsWithStrings)) + ' columns contain strings out of ' + str(len(TotalColumns)) + ' columns')\n",
    "    if (len(SensorsWithStrings)/len(TotalColumns)) > 0.5:\n",
    "        print ('this process will take some time depending of the size of the file and the PC resources')\n",
    "    \n",
    "    # Dropping DATETIME index to merge df1 and df2\n",
    "    df1 = df1.reset_index(drop=False)\n",
    "    df2 = df2.reset_index(drop=False)\n",
    "    \n",
    "    # Variable initialization\n",
    "    j = 0\n",
    "    StringListForAllSensors = []\n",
    "\n",
    "    # Create dictionary from dataframe columns (sensors) that have strings only\n",
    "    SensorDictionary = {}.fromkeys(SensorsWithStrings, [])\n",
    "\n",
    "    # Loop to go thru each column and convert the characters string to numbers    \n",
    "    for j in range(len(SensorsWithStrings)):\n",
    "        # from IPython.core.debugger import Tracer\n",
    "        # Tracer()() #this one triggers the debugger\n",
    "            \n",
    "        %time\n",
    "        # iterate thru each column in the dataframe\n",
    "        # for j in range(len(list(SensorDictionary))):\n",
    "        # update sensor name for each column\n",
    "        Sensor = list(SensorDictionary)[j]\n",
    "        print ('Processing Sensor: ' + Sensor)\n",
    "        # Clear List of String for each Sensor\n",
    "        SensorStringResult = []\n",
    "        # Iterate thru each row value\n",
    "\n",
    "        # Get rows that have null in the actual sensor column\n",
    "        # df2_with_null = df2_with_null[df2_with_null['tagname 1']=='null']['tagname 1']\n",
    "        result = df2_with_nan[df2_with_nan[Sensor].isnull()][Sensor]\n",
    "\n",
    "        # Convert list of nulls to dataframe and reset the datetime index\n",
    "        result_df = pd.DataFrame(result)\n",
    "        result_df = result_df.reset_index()\n",
    "\n",
    "        # Getting list of Strings for Sensor\n",
    "        SensorStringResult = df2[df2['Date TIme'].isin(result_df.loc[:,\"Date TIme\"].values.tolist())][Sensor]\n",
    "        \n",
    "        # Adding Strings to Sensor in Sensor Dictionary\n",
    "        SensorDictionary[Sensor] = list(set(SensorStringResult))\n",
    "\n",
    "        # Adding String for Sensor to General String List\n",
    "        StringListForAllSensors.extend(SensorStringResult)\n",
    "        print (SensorDictionary)\n",
    "    print (SensorDictionary)\n",
    "    # Removing Duplicate Strings\n",
    "    StringListForAllSensors = list(set(StringListForAllSensors))\n",
    "    print (StringListForAllSensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tagname 2'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(SensorDictionary)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tagname 1    float64\n",
       "tagname 2    float64\n",
       "tagname 3    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_nan.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagname 1</th>\n",
       "      <th>tagname 2</th>\n",
       "      <th>tagname 3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date TIme</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:00:00</th>\n",
       "      <td>158.78685</td>\n",
       "      <td>158.78685</td>\n",
       "      <td>158.78685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:05:00</th>\n",
       "      <td>158.68770</td>\n",
       "      <td>158.68770</td>\n",
       "      <td>158.68770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:10:00</th>\n",
       "      <td>158.70590</td>\n",
       "      <td>158.70590</td>\n",
       "      <td>158.70590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:15:00</th>\n",
       "      <td>158.96510</td>\n",
       "      <td>158.96510</td>\n",
       "      <td>158.96510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:20:00</th>\n",
       "      <td>158.48380</td>\n",
       "      <td>158.48380</td>\n",
       "      <td>158.48380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tagname 1  tagname 2  tagname 3\n",
       "Date TIme                                           \n",
       "01/01/2014 00:00:00  158.78685  158.78685  158.78685\n",
       "01/01/2014 00:05:00  158.68770  158.68770  158.68770\n",
       "01/01/2014 00:10:00  158.70590  158.70590  158.70590\n",
       "01/01/2014 00:15:00  158.96510  158.96510  158.96510\n",
       "01/01/2014 00:20:00  158.48380  158.48380  158.48380"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2_with_null = df2_with_nan.fillna(value='null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date TIme</th>\n",
       "      <th>tagname 1</th>\n",
       "      <th>tagname 2</th>\n",
       "      <th>tagname 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2014 00:00:00</td>\n",
       "      <td>158.787</td>\n",
       "      <td>158.787</td>\n",
       "      <td>158.78685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2014 00:05:00</td>\n",
       "      <td>158.688</td>\n",
       "      <td>158.688</td>\n",
       "      <td>158.68770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2014 00:10:00</td>\n",
       "      <td>158.706</td>\n",
       "      <td>158.706</td>\n",
       "      <td>158.70590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2014 00:15:00</td>\n",
       "      <td>158.965</td>\n",
       "      <td>158.965</td>\n",
       "      <td>158.96510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2014 00:20:00</td>\n",
       "      <td>158.484</td>\n",
       "      <td>158.484</td>\n",
       "      <td>158.48380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01/01/2014 00:25:00</td>\n",
       "      <td>null</td>\n",
       "      <td>158.714</td>\n",
       "      <td>158.71440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01/01/2014 00:30:00</td>\n",
       "      <td>158.679</td>\n",
       "      <td>158.679</td>\n",
       "      <td>158.67910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01/01/2014 00:35:00</td>\n",
       "      <td>158.628</td>\n",
       "      <td>158.628</td>\n",
       "      <td>158.62830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01/01/2014 00:40:00</td>\n",
       "      <td>159.128</td>\n",
       "      <td>159.128</td>\n",
       "      <td>159.12770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01/01/2014 00:45:00</td>\n",
       "      <td>null</td>\n",
       "      <td>158.884</td>\n",
       "      <td>158.88440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01/01/2014 00:50:00</td>\n",
       "      <td>158.731</td>\n",
       "      <td>158.731</td>\n",
       "      <td>158.73120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01/01/2014 00:55:00</td>\n",
       "      <td>158.901</td>\n",
       "      <td>null</td>\n",
       "      <td>158.73120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01/01/2014 01:00:00</td>\n",
       "      <td>158.921</td>\n",
       "      <td>158.921</td>\n",
       "      <td>158.92120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01/01/2014 01:05:00</td>\n",
       "      <td>158.658</td>\n",
       "      <td>158.658</td>\n",
       "      <td>158.65840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01/01/2014 01:10:00</td>\n",
       "      <td>158.789</td>\n",
       "      <td>158.789</td>\n",
       "      <td>158.78940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01/01/2014 01:15:00</td>\n",
       "      <td>159.045</td>\n",
       "      <td>159.045</td>\n",
       "      <td>159.04520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01/01/2014 01:20:00</td>\n",
       "      <td>159.24</td>\n",
       "      <td>159.24</td>\n",
       "      <td>159.24040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01/01/2014 01:25:00</td>\n",
       "      <td>158.873</td>\n",
       "      <td>158.873</td>\n",
       "      <td>158.87320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date TIme tagname 1 tagname 2  tagname 3\n",
       "0   01/01/2014 00:00:00   158.787   158.787  158.78685\n",
       "1   01/01/2014 00:05:00   158.688   158.688  158.68770\n",
       "2   01/01/2014 00:10:00   158.706   158.706  158.70590\n",
       "3   01/01/2014 00:15:00   158.965   158.965  158.96510\n",
       "4   01/01/2014 00:20:00   158.484   158.484  158.48380\n",
       "5   01/01/2014 00:25:00      null   158.714  158.71440\n",
       "6   01/01/2014 00:30:00   158.679   158.679  158.67910\n",
       "7   01/01/2014 00:35:00   158.628   158.628  158.62830\n",
       "8   01/01/2014 00:40:00   159.128   159.128  159.12770\n",
       "9   01/01/2014 00:45:00      null   158.884  158.88440\n",
       "10  01/01/2014 00:50:00   158.731   158.731  158.73120\n",
       "11  01/01/2014 00:55:00   158.901      null  158.73120\n",
       "12  01/01/2014 01:00:00   158.921   158.921  158.92120\n",
       "13  01/01/2014 01:05:00   158.658   158.658  158.65840\n",
       "14  01/01/2014 01:10:00   158.789   158.789  158.78940\n",
       "15  01/01/2014 01:15:00   159.045   159.045  159.04520\n",
       "16  01/01/2014 01:20:00    159.24    159.24  159.24040\n",
       "17  01/01/2014 01:25:00   158.873   158.873  158.87320"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_null.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = df2_with_nan[df2_with_nan['tagname 1'].isnull()]['tagname 1']\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df = result_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date TIme</th>\n",
       "      <th>tagname 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2014 00:25:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2014 00:45:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date TIme  tagname 1\n",
       "0  01/01/2014 00:25:00        NaN\n",
       "1  01/01/2014 00:45:00        NaN"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01/01/2014 00:25:00', '01/01/2014 00:45:00']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[:,\"Date TIme\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to query dataframe  with multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SensorStringResult = df2[df2['Date TIme'].isin(result_df.loc[:,\"Date TIme\"].values.tolist())]['tagname 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SensorStringList = SensorStringResult.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'hello there']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SensorStringList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df2_with_nan.isnull().any(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df2_with_nan.isnull().any(axis=0))\n",
    "df3 = df3.reset_index()\n",
    "SensorsWithStrings = df3[df3[0]==True]['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SensorDictionary = {}.fromkeys(SensorsWithStrings, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tagname 1': [], 'tagname 2': []}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SensorDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tagname 2'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(SensorDictionary)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagname 1', 'tagname 2', 'tagname 3']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_nan[df2_with_nan.isnull().any(axis=1)].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01/01/2014 00:25:00'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['Date TIme'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame(df2[df2['Date TIme']==result_df['Date TIme'][0]]['tagname 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['tagname 1'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(n):\n",
    "    csvfile = CSVPath1 + \"/\" + CSVFileList[i]\n",
    "    print(\"Loading Segment: %s\" % CSVFileList[i])\n",
    "\n",
    "    # In[43]:\n",
    "    print ('Time Loading ' + CSVFileList[i] + ' file')\n",
    "    %time df = pd.read_csv(csvfile, index_col=False, sep=',', low_memory=False)\n",
    "    \n",
    "    # In[51]:\n",
    "    # Need to do this to avoid \n",
    "    df = df.copy()\n",
    "    # Change new datetime column to datetime format\n",
    "    df['Date TIme'] = pd.to_datetime(df['Date TIme'])\n",
    "    # In[53]:\n",
    "    # Change datetime column format to look like 01/31/2015 0:00:00\n",
    "    df['Date TIme'] = df['Date TIme'].dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "    # Code to do Transposing\n",
    "    # Create two dataframes df1 only with tags and descriptions. df2 tag with values\n",
    "    df1 = df[0:1]  # FIRST ROW\n",
    "    df2 = df[1:len(df)]  # SECOND TO LAST ROW\n",
    "    \n",
    "    # Indexing dataframe df1\n",
    "    df1 = df1.set_index('Date TIme')\n",
    "\n",
    "    # Indexing dataframe df2\n",
    "    df2 = df2.set_index('Date TIme')\n",
    "\n",
    "    # Convert columns to numbers those that has string wont be converted\n",
    "    df2_with_null = df2.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "    # Here we filter the columns that are objects and create a dataframe with those columns\n",
    "    colsObject = df2.select_dtypes(include=['object']).columns\n",
    "    TotalColumns = df2.columns\n",
    "    \n",
    "    # print status\n",
    "    print (str(len(colsObject)) + ' columns contain strings out of ' + str(len(TotalColumns)) + ' columns')\n",
    "    print ('this process will take some time depending of the size of the file and the PC resources')\n",
    "    \n",
    "    # Loop to go thru each column and convert the characters string to numbers\n",
    "    y = 0\n",
    "    for y in range(len(colsObject)):\n",
    "        # We don't want to change null to number\n",
    "        # from IPython.core.debugger import Tracer\n",
    "        # Tracer()() #this one triggers the debugger\n",
    "            \n",
    "        # Create dictionary from dataframe columns (sensors)\n",
    "        SensorDictionary = {}.fromkeys(list(df1), [])\n",
    "        %time\n",
    "        # iterate thru each column in the dataframe\n",
    "        for j in range(len(list(SensorDictionary))):\n",
    "            # update sensor name for each column\n",
    "            Sensor = list(SensorDictionary)[j]\n",
    "            print ('Processing Sensor: ' + Sensor)\n",
    "            # Clear List of String for each Sensor\n",
    "            StringList = []\n",
    "            # Iterate thru each row value\n",
    "            for x in range(len(df2)):\n",
    "                try:\n",
    "                    # df2.iloc[i].apply(lambda x: pd.to_numeric(x, errors='raise'))\n",
    "                    df2[Sensor].iloc[x] = float(df2[Sensor].iloc[x])\n",
    "                except ValueError:\n",
    "                    # Add String to list\n",
    "                    StringList.append(str(df2[Sensor].iloc[x]))\n",
    "                    print ('Can not convert '+ str(df2[Sensor].iloc[x]) + ' to number' + ' in row: ' + str(x) + ' for sensor: ' + Sensor)\n",
    "                # Add distinct Strings to the sensor Dictionary\n",
    "                SensorDictionary[Sensor] = list(set(StringList))\n",
    "            print ('Sensors with String data for file: ' + CSVFileList[i])\n",
    "            print (SensorDictionary[Sensor])\n",
    "        print (SensorDictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now we have to replace string for specific text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if pd.unique(df2[[colsObject[1]]].values.ravel()) != 'null':\n",
    "# Here we are assign a integer to each unique row value, the integer will increase\n",
    "# from 0 to x where x is the total unique values\n",
    "    # df2[[df2.columns.get_loc(colsObject[y])]] = pd.factorize(df2.iloc[:,df2.columns.get_loc(colsObject[y])])[0]\n",
    "\n",
    "# Replacing known test to null\n",
    "df2.replace({'test': 'null', 'hello there': 'null', 'wow more text': 'null'}, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now we convert the data to linear format Previse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={'Date TIme': 'DATETIME'})\n",
    "df2 = df2.rename(columns={'Date TIme': 'DATETIME'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dropping DATETIME index to merge df1 and df2\n",
    "df1 = df1.reset_index(drop=False)\n",
    "df2 = df2.reset_index(drop=False)\n",
    "\n",
    "# Converting Historian files to VTQ format (DATETIME, TAGNAME, DESCRIPTION, VALUE)\n",
    "mdf = pd.merge(pd.melt(df1, id_vars=['DATETIME'], var_name='TAGNAME',\n",
    "                       value_name='DESCRIPTION')[['TAGNAME', 'DESCRIPTION']],\n",
    "               pd.melt(df2, id_vars=['DATETIME'], var_name='TAGNAME',\n",
    "                       value_name='VALUE'),\n",
    "               on=['TAGNAME'])\n",
    "\n",
    "# Sort columns by VTQ format\n",
    "mdf = mdf[['DATETIME', 'TAGNAME', 'DESCRIPTION', 'VALUE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Here we split the CSV data by file and each file will contain 1 million rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exporting PHD Tag CSV file\n",
    "j = 1\n",
    "rows = 1000000\n",
    "totalRows = len(mdf)\n",
    "loops = math.ceil(totalRows/rows) + 1\n",
    "\n",
    "for j in range(loops): #need to round this\n",
    "    a = (rows*j) - rows\n",
    "    if totalRows <= rows:\n",
    "        b = totalRows\n",
    "        print('Exporting ' + str(CSVFileList[i].replace('.csv', '')) + ' Historian File')\n",
    "        print(\"\")\n",
    "        mdf[a:b].to_csv(CSVPath1 + '/' + str(CSVFileList[i].replace('.csv', '')) + '_Formatted.csv', index=False)\n",
    "    else:\n",
    "        if (rows*j) >= totalRows:\n",
    "            b = totalRows\n",
    "            print('Exporting ' + str(CSVFileList[i].replace('.csv', '')) + ' chunk' + str(j) + ' Historian File')\n",
    "            print(\"\")\n",
    "            mdf[a:b].to_csv(CSVPath1 + '/' + str(CSVFileList[i].replace('.csv', '')) + '_Formatted_chunk' + str(j) + '.csv', index=False)\n",
    "        else:\n",
    "            b = (rows*j) - 1\n",
    "            print('Exporting ' + str(CSVFileList[i].replace('.csv', '')) + ' chunk' + str(j) + ' Historian File')\n",
    "            print(\"\")\n",
    "            mdf[a:b].to_csv(CSVPath1 + '/' + str(CSVFileList[i].replace('.csv', '')) + '_Formatted_chunk' + str(j) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
