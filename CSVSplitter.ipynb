{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# latest update\n",
    "# April 26, 2017\n",
    "# Changes done by: Jimmy Vivas\n",
    "# Added code description\n",
    "\n",
    "# This code was developed by Jimmy Vivas\n",
    "\n",
    "# The code will take all CSv files from a specific directory and process them at the same time\n",
    "# The code will get replace strings in the values for numeric data\n",
    "#   It will assign an integer value for each distinct string for each column (sensor)\n",
    "#   The integer value will be reset it for each sensor\n",
    "#   The code does not evaluare wether or not the sensor should stay. THe analyst will make this decision\n",
    "#   Using Previse or any other tool\n",
    "# The code will split the csv file if the result is more than 1MM rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSVFileList = []\n",
    "NanPHDTagList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mac Path\n",
    "#CSVPath1 =  '/Users/jvivas/Documents/XMT Baytwon Sensor Data' \\\n",
    "#            '/Sensor Data/Testing'\n",
    "\n",
    "CSVPath1 = '/Users/jvivas/Documents/Aspen/PTT GC PoC/Sensor Data/A210 - Quench Oil Tower/To Be Processed'\n",
    "\n",
    "# Windows Path\n",
    "# CSVPath1 = 'C:/Users/jvivas/Dropbox/Mtell Customer Projects/XOM BayTown RHC MEA Tower Foaming/Sensor Data/' \\\n",
    "#           'To be Processed'\n",
    "\n",
    "# CSVPath1 = 'C:/Mtell/Projects/XOM Baytown POC/Sensor Data/ToBeFormatted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSVFileListAll = listdir(CSVPath1)\n",
    "m = len(CSVFileListAll)\n",
    "for i in range(m):\n",
    "    fileNameStr = CSVFileListAll[i]\n",
    "    fileStr = fileNameStr.split('.')[0]\n",
    "    fileExt = fileNameStr.split('.')[1]\n",
    "    if fileExt == \"csv\":\n",
    "        CSVFileList.append(fileNameStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(CSVFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvfile = CSVPath1 + \"/\" + CSVFileList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csvfile, index_col=False, sep=',', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[0:1000000].to_csv(CSVPath1 + '/' + str(CSVFileList[i].replace('.csv', '')) + '_1MM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Segment: A210.csv\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(n):\n",
    "    csvfile = CSVPath1 + \"/\" + CSVFileList[i]\n",
    "    print(\"Loading Segment: %s\" % CSVFileList[i])\n",
    "\n",
    "    # In[43]:\n",
    "    df = pd.read_csv(csvfile, index_col=False, sep=',', low_memory=False)\n",
    "\n",
    "    # Exporting PHD Tag CSV file\n",
    "    j = 1\n",
    "    rows = 1000000\n",
    "    totalRows = len(df)\n",
    "    loops = math.ceil(totalRows/rows) + 1\n",
    "\n",
    "    for j in range(loops): #need to round this\n",
    "        a = (rows*j) - rows\n",
    "        if totalRows <= rows:\n",
    "            b = totalRows\n",
    "            print('Splitting ' + str(CSVFileList[i].replace('.csv', '')) + ' Historian File')\n",
    "            print(\"\")\n",
    "            df[a:b].to_csv(CSVPath1 + '/' + str(CSVFileList[i].replace('.csv', '')) + '.csv', index=False)\n",
    "        else:\n",
    "            if (rows*j) >= totalRows:\n",
    "                b = totalRows\n",
    "                print('Splitting ' + str(CSVFileList[i].replace('.csv', '')) + '_' + str(j) + ' Historian File')\n",
    "                print(\"\")\n",
    "                df[a:b].to_csv(CSVPath1 + '/' + str(CSVFileList[i].replace('.csv', '')) + '_' + str(j) + '.csv', index=False)\n",
    "            else:\n",
    "                b = (rows*j) - 1\n",
    "                print('Splitting ' + str(CSVFileList[i].replace('.csv', '')) + ' chunk' + str(j) + ' Historian File')\n",
    "                print(\"\")\n",
    "                df[a:b].to_csv(CSVPath1 + '/' + str(CSVFileList[i].replace('.csv', '')) + '_F' + str(j) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
