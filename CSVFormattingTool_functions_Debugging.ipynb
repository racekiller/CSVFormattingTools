{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# latest update\n",
    "# April 26, 2017\n",
    "# Changes done by: Jimmy Vivas\n",
    "# Added code description\n",
    "\n",
    "# This code was developed by Jimmy Vivas\n",
    "\n",
    "# The code will take all CSv files from a specific directory and process them at the same Time\n",
    "# The code will get replace strings in the values for numeric data\n",
    "#   It will assign an integer value for each distinct string for each column (sensor)\n",
    "#   The integer value will be reset it for each sensor\n",
    "#   The code does not evaluare wether or not the sensor should stay. THe analyst will make this decision\n",
    "#   Using Previse or any other tool\n",
    "# The code will split the csv file if the result is more than 1MM rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mac Path\n",
    "#CSVPath1 =  '/Users/jvivas/Documents/XMT Baytwon Sensor Data' \\\n",
    "#            '/Sensor Data/Testing'\n",
    "\n",
    "# CSVPath1 = '/Users/jvivas/Documents/Aspen/GASCO/Sensor Data/To Be Processed'\n",
    "\n",
    "# Windows Path\n",
    "CSVPath1 = 'C:/Users/vivasj/Documents/Aspen/PTT GC/C002B/DATA/To be Processed'\n",
    "FinalPath = 'C:/Users/vivasj/Documents/Aspen/PTT GC/C002B/DATA/Processed'\n",
    "\n",
    "# CSVPath1 = 'C:/Mtell/Projects/XOM Baytown POC/Sensor Data/ToBeFormatted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSVFileList = []\n",
    "NanPHDTagList = []\n",
    "CSVFileListAll = listdir(CSVPath1)\n",
    "\n",
    "m = len(CSVFileListAll)\n",
    "\n",
    "for i in range(m):\n",
    "    fileNameStr = CSVFileListAll[i]\n",
    "    fileStr = fileNameStr.split('.')[0]\n",
    "    fileExt = fileNameStr.split('.')[1]\n",
    "    if fileExt == \"csv\":\n",
    "        CSVFileList.append(fileNameStr)\n",
    "\n",
    "n = len(CSVFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncomment following cell for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetFileSize(file):\n",
    "    import os\n",
    "    csvFileStatInfo = os.stat(file)\n",
    "    csvFileSizeGB = csvFileStatInfo.st_size/1000000000\n",
    "    return(csvFileSizeGB)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RenameColumn(df2):\n",
    "# Ranane Date and time column to DATETIME\n",
    "    new_cols = ['DATETIME']\n",
    "    df2.rename(columns=dict(zip(df2.columns[[0]], new_cols)),inplace=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ApplyDateFormat(df2):\n",
    "\n",
    "    # duplicate df2 to apply date and time format \n",
    "    # df2 = df2.copy()    \n",
    "    # Change new datetime column to datetime format\n",
    "    df2['DATETIME'] = pd.to_datetime(df2['DATETIME'])    \n",
    "    # Change datetime column format to look like 01/31/2015 0:00:00\n",
    "    df2['DATETIME'] = df2['DATETIME'].dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitCSVFile_GetStrings(CSVFileWithPath, CSVFile):\n",
    "    chunksize = 25000\n",
    "\n",
    "    i = 0\n",
    "    j = 1\n",
    "    \n",
    "    SensorStringListAllChunks = []\n",
    "    StringListForAllSensors = []\n",
    "    StringListForEachChunk = []\n",
    "        \n",
    "    print ('Loading ' + CSVFile + ' file')\n",
    "    for df in pd.read_csv(CSVFileWithPath, chunksize=chunksize, iterator=True, low_memory=False):\n",
    "        # df = df.rename(columns={c: c.replace(' ', '') for c in df.columns}) \n",
    "        df.index += j\n",
    "        i+=1\n",
    "        j = df.index[-1] + 1\n",
    "        h = 0\n",
    "        \n",
    "        # Rename date and time column\n",
    "        print ('Renaming date and time column')\n",
    "        RenameColumn(df)\n",
    "\n",
    "        # Apply Date and time format to dataframe\n",
    "        print ('Applying date and time format')\n",
    "        ApplyDateFormat(df)\n",
    "\n",
    "        # Code to do Transposing\n",
    "        # Create two dataframes df1 only with tags and descriptions. df2 tag with values\n",
    "        if i == 1:\n",
    "            df1 = df[0:1]  # FIRST ROW\n",
    "            # Indexing dataframe df1\n",
    "            df1 = df1.set_index('DATETIME')\n",
    "        else:\n",
    "            if i > 1:\n",
    "                df1 = df1\n",
    "                \n",
    "        df2 = df[1:len(df)]  # SECOND TO LAST ROW\n",
    "\n",
    "        # Indexing dataframe df2\n",
    "        df2 = df2.set_index('DATETIME')\n",
    "        \n",
    "        # Export CSV chunk for each loop\n",
    "        print ('Exporting chunk' + str(i))\n",
    "        df.to_csv(CSVFileWithPath.replace('.csv', '') + '_chunk_ ' + str(i) + '.csv', index=True)\n",
    "        \n",
    "        print ('Getting the list for chunk' + str(i))\n",
    "        StringListForEachChunk = ExtractStrings(df1, df2)\n",
    "        \n",
    "        print ('These are all the strings found in the chunk ' + str(i) + ':' + str(StringListForEachChunk))\n",
    "        \n",
    "        SensorStringListAllChunks.extend(StringListForEachChunk)\n",
    "\n",
    "    SensorStringListAllChunks = list(set(SensorStringListAllChunks))\n",
    "    return(SensorStringListAllChunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExtractStrings(df2_1, df2_2):\n",
    "        \n",
    "    print ('Converting df to numeric')\n",
    "    # Convert columns to numbers those that has string wil be converted to numpy null = NaN\n",
    "    df2_with_nan = df2_2.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    # print (df2_2.head())\n",
    "    # print (df2_with_nan.head())\n",
    "    # Ge the list of sensors with Strings\n",
    "    df3 = pd.DataFrame(df2_with_nan.isnull().any(axis=0))\n",
    "    df3 = df3.reset_index()\n",
    "    SensorsWithStrings = df3[df3[0]==True]['index'].tolist()\n",
    "    \n",
    "    # Replace nan with 'null' and create new df\n",
    "    df2_with_null = df2_with_nan.fillna(value='null')\n",
    "    \n",
    "    # Here we filter the columns that are objects and create a dataframe with those columns\n",
    "    colsObject = df2_2.select_dtypes(include=['object']).columns\n",
    "    TotalColumns = df2_2.columns\n",
    "    \n",
    "    print ('Total columns with text: ' + str(TotalColumns))\n",
    "    print ('Sensors with text in their Values: ' + str(SensorsWithStrings))\n",
    "\n",
    "    AllSensorsStringList = []\n",
    "    \n",
    "    if len(SensorsWithStrings) == 0:\n",
    "        print ('No strings in this dataframe')\n",
    "    else:\n",
    "        # print (str(len(SensorsWithStrings)) + ' columns contain strings out of ' + str(len(TotalColumns)) + ' columns')\n",
    "        # if (len(SensorsWithStrings)/len(TotalColumns)) > 0.5:\n",
    "            # print ('this process will take some time depending of the size of the file and the PC resources')\n",
    "\n",
    "        # Dropping DATETIME index to merge df1 and df2\n",
    "        df2_1 = df2_1.reset_index(drop=False)\n",
    "        df2_2 = df2_2.reset_index(drop=False)\n",
    "        \n",
    "        # Variable initialization\n",
    "        j = 0\n",
    "\n",
    "        StringListForCurrentSensor = []\n",
    "\n",
    "        # Create dictionary from dataframe columns (sensors) that have strings only\n",
    "        SensorDictionary = {}.fromkeys(SensorsWithStrings, [])\n",
    "        \n",
    "        # Loop to go thru each column and convert the characters string to numbers    \n",
    "        for j in range(len(SensorsWithStrings)):\n",
    "            # from IPython.core.debugger import Tracer\n",
    "            # Tracer()() #this one triggers the debugger\n",
    "\n",
    "            # iterate thru each column in the dataframe\n",
    "            # for j in range(len(list(SensorDictionary))):\n",
    "            # update sensor name for each column\n",
    "            Sensor = list(SensorDictionary)[j]\n",
    "\n",
    "            print ('Processing Sensor: ' + Sensor)\n",
    "            # Clear List of String for each Sensor\n",
    "            SensorStringResult = []\n",
    "\n",
    "            # Get rows that have null in the actual sensor column\n",
    "            result = df2_with_nan[df2_with_nan[Sensor].isnull()][Sensor]\n",
    "\n",
    "            # Convert list of nulls to dataframe and reset the datetime index\n",
    "            result_df = pd.DataFrame(result)\n",
    "            result_df = result_df.reset_index()\n",
    "            \n",
    "            # print ('printing result_df')\n",
    "            # print (result_df.head())\n",
    "            # print ('printing df2_2')\n",
    "            # print (df2_2.head())\n",
    "            # debugging\n",
    "            # print (result_df)\n",
    "            # debugging\n",
    "\n",
    "            # Filtering rows with String for each sensor\n",
    "            SensorStringResult = df2_2[df2_2['DATETIME'].isin(result_df.loc[:,\"DATETIME\"].values.tolist())][Sensor]\n",
    "\n",
    "            # Adding Strings to Sensor in Sensor Dictionary\n",
    "            # I think that when due to a bug the dictionary become too big it stops growing...\n",
    "            # SensorDictionary[Sensor] = list(set(SensorStringResult))\n",
    "            StringListForCurrentSensor = list(set(SensorStringResult))\n",
    "            \n",
    "            # Debugging\n",
    "            # print (list(set(SensorStringResult)))\n",
    "            # Debugging\n",
    "            \n",
    "            # print ('Sensor: ' + Sensor + ' Processed')\n",
    "\n",
    "            # Adding String for Sensor to General String List\n",
    "            AllSensorsStringList.extend(StringListForCurrentSensor)\n",
    "\n",
    "            # Removing Duplicate Strings\n",
    "            AllSensorsStringList = list(set(AllSensorsStringList))\n",
    "            \n",
    "            print ('These are all the strings found in Sensor ' + Sensor + ': ' + str(StringListForCurrentSensor))\n",
    "    return (AllSensorsStringList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SetIndex(df2):\n",
    "        # Code to do Transposing\n",
    "    # Create two dataframes df1 only with tags and descriptions. df2 tag with values\n",
    "    df2_1 = df2[0:1]  # FIRST ROW\n",
    "    df2_2 = df2[1:len(df2)]  # SECOND TO LAST ROW\n",
    "    \n",
    "    # Indexing dataframe df1\n",
    "    df2_1 = df2_1.set_index('DATETIME')\n",
    "\n",
    "    # Indexing dataframe df2\n",
    "    df2_2 = df2_2.set_index('DATETIME')\n",
    "    return(df2_1, df2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadCSV(FileAndPath, file):\n",
    "    print ('Loading ' + file)\n",
    "    df2 = pd.read_csv(FileAndPath, low_memory=False)\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FormatToPrevise(df2_1, df2_2):\n",
    "    # Dropping DATETime index to merge df1 and df2\n",
    "    df2_1 = df2_1.reset_index(drop=False)\n",
    "    df2_2 = df2_2.reset_index(drop=False)\n",
    "\n",
    "    # Converting Historian files to VTQ format (DATETime, TAGNAME, DESCRIPTION, VALUE)\n",
    "    mdf = pd.merge(pd.melt(df2_1, id_vars=['DATETIME'], var_name='TAGNAME',\n",
    "                           value_name='DESCRIPTION')[['TAGNAME', 'DESCRIPTION']],\n",
    "                   pd.melt(df2_2, id_vars=['DATETIME'], var_name='TAGNAME',\n",
    "                           value_name='VALUE'),\n",
    "                   on=['TAGNAME'])\n",
    "\n",
    "    # Sort columns by VTQ format\n",
    "    mdf = mdf[['DATETIME', 'TAGNAME', 'DESCRIPTION', 'VALUE']]\n",
    "    \n",
    "    return (mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitPreviseFormatCSVFile(mdf):\n",
    "    # Exporting PHD Tag CSV file\n",
    "    i = 0\n",
    "    rows = 1000000\n",
    "    totalRows = len(mdf)\n",
    "    loops = math.ceil(totalRows/rows) + 1\n",
    "\n",
    "    if totalRows > 1000000:\n",
    "        for j in range(loops): #need to round this\n",
    "            j = j + 1\n",
    "            print (str(j))\n",
    "            a = (rows*j) - rows\n",
    "            if totalRows <= rows:\n",
    "                b = totalRows\n",
    "                print('Exporting ' + str(CSVFileList[i].replace('.csv', '')) + ' Historian File')\n",
    "                print(\"\")\n",
    "                mdf[a:b].to_csv(FinalPath + '/' + str(CSVFileList[i].replace('.csv', '')) + '_Formatted.csv', index=False)\n",
    "            else:\n",
    "                if (rows*j) >= totalRows:\n",
    "                    b = totalRows\n",
    "                    print('Exporting ' + str(CSVFileList[i].replace('.csv', '')) + ' chunk' + str(j) + ' Historian File')\n",
    "                    print(\"\")\n",
    "                    mdf[a:b].to_csv(FinalPath + '/' + str(CSVFileList[i].replace('.csv', '')) + '_Formatted_chunk' + str(j) + '.csv', index=False)\n",
    "                else:\n",
    "                    b = (rows*j) - 1\n",
    "                    print('Exporting ' + str(CSVFileList[i].replace('.csv', '')) + ' chunk' + str(j) + ' Historian File')\n",
    "                    print(\"\")\n",
    "                    mdf[a:b].to_csv(FinalPath + '/' + str(CSVFileList[i].replace('.csv', '')) + '_Formatted_chunk' + str(j) + '.csv', index=False)\n",
    "    else:\n",
    "        mdf.to_csv(FinalPath + '/' + str(CSVFileList[0].replace('.csv', '')) + '_Formatted' + '.csv', index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Main Code to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200C2_Erroring_3Columns.csv\n"
     ]
    }
   ],
   "source": [
    "CSVFile = CSVFileList[0]\n",
    "CSVFileWithPath = CSVPath1 + \"/\" + CSVFileList[0]\n",
    "\n",
    "csvFileSizeGB = GetFileSize(CSVFileWithPath)\n",
    "\n",
    "df2 = LoadCSV(CSVFileWithPath, CSVFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming date and time column\n",
      "Applying date and time format\n"
     ]
    }
   ],
   "source": [
    "# Rename date and time column\n",
    "print ('Renaming date and time column')\n",
    "RenameColumn(df2)\n",
    "# Apply Date and time format to dataframe\n",
    "print ('Applying date and time format')\n",
    "ApplyDateFormat(df2)\n",
    "\n",
    "# Apply Index and create two dataframes\n",
    "df2_1, df2_2 = SetIndex(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1-200TI727HA.PV</th>\n",
       "      <th>A1-200TI727HB.PV</th>\n",
       "      <th>905II259BI.PV</th>\n",
       "      <th>905II259B.CPV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>Motor bearing Temp</td>\n",
       "      <td>Motor bearing Temp NDE(SPARE)</td>\n",
       "      <td></td>\n",
       "      <td>NET GAS COMP 200-C2B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A1-200TI727HA.PV               A1-200TI727HB.PV 905II259BI.PV  \\\n",
       "DATETIME                                                                    \n",
       "NaT       Motor bearing Temp  Motor bearing Temp NDE(SPARE)                 \n",
       "\n",
       "                 905II259B.CPV  \n",
       "DATETIME                        \n",
       "NaT       NET GAS COMP 200-C2B  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1-200TI727HA.PV</th>\n",
       "      <th>A1-200TI727HB.PV</th>\n",
       "      <th>905II259BI.PV</th>\n",
       "      <th>905II259B.CPV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:00:00</th>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>277.2757568</td>\n",
       "      <td>274.1443481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:05:00</th>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>269.463562</td>\n",
       "      <td>272.9598083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:10:00</th>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>261.2208862</td>\n",
       "      <td>253.5136414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:15:00</th>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>268.6708069</td>\n",
       "      <td>270.455658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:20:00</th>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>276.6998901</td>\n",
       "      <td>269.4458313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    A1-200TI727HA.PV A1-200TI727HB.PV 905II259BI.PV  \\\n",
       "DATETIME                                                              \n",
       "01/01/2014 00:00:00          No Data          No Data   277.2757568   \n",
       "01/01/2014 00:05:00          No Data          No Data    269.463562   \n",
       "01/01/2014 00:10:00          No Data          No Data   261.2208862   \n",
       "01/01/2014 00:15:00          No Data          No Data   268.6708069   \n",
       "01/01/2014 00:20:00          No Data          No Data   276.6998901   \n",
       "\n",
       "                    905II259B.CPV  \n",
       "DATETIME                           \n",
       "01/01/2014 00:00:00   274.1443481  \n",
       "01/01/2014 00:05:00   272.9598083  \n",
       "01/01/2014 00:10:00   253.5136414  \n",
       "01/01/2014 00:15:00    270.455658  \n",
       "01/01/2014 00:20:00   269.4458313  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_with_nan = df2_2.apply(lambda x: pd.to_numeric(x, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1-200TI727HA.PV    True\n",
       "A1-200TI727HB.PV    True\n",
       "905II259BI.PV       True\n",
       "905II259B.CPV       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_nan.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df2_with_nan.isnull().any(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1-200TI727HA.PV</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1-200TI727HB.PV</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905II259BI.PV</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905II259B.CPV</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "A1-200TI727HA.PV  True\n",
       "A1-200TI727HB.PV  True\n",
       "905II259BI.PV     True\n",
       "905II259B.CPV     True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1-200TI727HA.PV</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1-200TI727HB.PV</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>905II259BI.PV</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905II259B.CPV</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index     0\n",
       "0  A1-200TI727HA.PV  True\n",
       "1  A1-200TI727HB.PV  True\n",
       "2     905II259BI.PV  True\n",
       "3     905II259B.CPV  True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1-200TI727HA.PV', 'A1-200TI727HB.PV', '905II259BI.PV', '905II259B.CPV']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SensorsWithStrings = df3[df3[0]==True]['index'].tolist()\n",
    "SensorsWithStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_with_null = df2_with_nan.fillna(value='null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colsObject = df2_2.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TotalColumns = df2_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllSensorsStringList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_1 = df2_1.reset_index(drop=False)\n",
    "df2_2 = df2_2.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StringListForCurrentSensor = []\n",
    "\n",
    "# Create dictionary from dataframe columns (sensors) that have strings only\n",
    "SensorDictionary = {}.fromkeys(SensorsWithStrings, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'905II259B.CPV': [],\n",
       " '905II259BI.PV': [],\n",
       " 'A1-200TI727HA.PV': [],\n",
       " 'A1-200TI727HB.PV': []}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SensorDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sensor = list(SensorDictionary)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A1-200TI727HA.PV'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sensor = '905II259BI.PV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1-200TI727HA.PV</th>\n",
       "      <th>A1-200TI727HB.PV</th>\n",
       "      <th>905II259BI.PV</th>\n",
       "      <th>905II259B.CPV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>09/30/2016 23:40:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.999699</td>\n",
       "      <td>229.224930</td>\n",
       "      <td>229.250046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09/30/2016 23:45:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.999699</td>\n",
       "      <td>233.359192</td>\n",
       "      <td>233.421692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09/30/2016 23:50:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.999699</td>\n",
       "      <td>280.176605</td>\n",
       "      <td>280.745300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09/30/2016 23:55:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.999699</td>\n",
       "      <td>255.031662</td>\n",
       "      <td>253.203873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/10/2016 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.999699</td>\n",
       "      <td>263.551819</td>\n",
       "      <td>263.930939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A1-200TI727HA.PV  A1-200TI727HB.PV  905II259BI.PV  \\\n",
       "DATETIME                                                                 \n",
       "09/30/2016 23:40:00               NaN         51.999699     229.224930   \n",
       "09/30/2016 23:45:00               NaN         51.999699     233.359192   \n",
       "09/30/2016 23:50:00               NaN         51.999699     280.176605   \n",
       "09/30/2016 23:55:00               NaN         51.999699     255.031662   \n",
       "01/10/2016 00:00:00               NaN         51.999699     263.551819   \n",
       "\n",
       "                     905II259B.CPV  \n",
       "DATETIME                            \n",
       "09/30/2016 23:40:00     229.250046  \n",
       "09/30/2016 23:45:00     233.421692  \n",
       "09/30/2016 23:50:00     280.745300  \n",
       "09/30/2016 23:55:00     253.203873  \n",
       "01/10/2016 00:00:00     263.930939  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_nan.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATETIME\n",
       "02/16/2014 05:20:00   NaN\n",
       "04/07/2014 17:45:00   NaN\n",
       "04/28/2014 09:55:00   NaN\n",
       "04/28/2014 10:00:00   NaN\n",
       "04/28/2014 10:05:00   NaN\n",
       "04/28/2014 10:10:00   NaN\n",
       "04/28/2014 10:15:00   NaN\n",
       "04/28/2014 10:20:00   NaN\n",
       "04/28/2014 10:25:00   NaN\n",
       "04/28/2014 21:50:00   NaN\n",
       "04/28/2014 21:55:00   NaN\n",
       "04/28/2014 22:00:00   NaN\n",
       "04/28/2014 22:05:00   NaN\n",
       "04/28/2014 22:10:00   NaN\n",
       "04/28/2014 22:15:00   NaN\n",
       "04/28/2014 22:20:00   NaN\n",
       "04/28/2014 22:25:00   NaN\n",
       "04/28/2014 22:30:00   NaN\n",
       "04/28/2014 22:35:00   NaN\n",
       "04/28/2014 22:40:00   NaN\n",
       "04/28/2014 22:45:00   NaN\n",
       "04/28/2014 22:50:00   NaN\n",
       "04/28/2014 22:55:00   NaN\n",
       "04/28/2014 23:00:00   NaN\n",
       "04/28/2014 23:05:00   NaN\n",
       "04/28/2014 23:10:00   NaN\n",
       "04/28/2014 23:15:00   NaN\n",
       "04/28/2014 23:20:00   NaN\n",
       "04/28/2014 23:25:00   NaN\n",
       "04/28/2014 23:30:00   NaN\n",
       "                       ..\n",
       "04/28/2015 00:10:00   NaN\n",
       "04/28/2015 00:15:00   NaN\n",
       "04/28/2015 00:20:00   NaN\n",
       "04/28/2015 00:25:00   NaN\n",
       "04/28/2015 00:30:00   NaN\n",
       "06/13/2015 11:55:00   NaN\n",
       "06/13/2015 12:00:00   NaN\n",
       "06/13/2015 12:05:00   NaN\n",
       "07/07/2015 15:35:00   NaN\n",
       "01/17/2016 15:45:00   NaN\n",
       "08/04/2016 15:05:00   NaN\n",
       "08/04/2016 15:10:00   NaN\n",
       "08/04/2016 15:15:00   NaN\n",
       "08/04/2016 15:20:00   NaN\n",
       "07/30/2016 09:45:00   NaN\n",
       "07/30/2016 09:50:00   NaN\n",
       "07/30/2016 09:55:00   NaN\n",
       "07/30/2016 10:00:00   NaN\n",
       "07/30/2016 10:05:00   NaN\n",
       "07/30/2016 10:10:00   NaN\n",
       "07/30/2016 10:15:00   NaN\n",
       "07/30/2016 10:20:00   NaN\n",
       "08/15/2016 20:25:00   NaN\n",
       "08/15/2016 20:30:00   NaN\n",
       "08/15/2016 20:35:00   NaN\n",
       "08/15/2016 20:40:00   NaN\n",
       "08/15/2016 20:45:00   NaN\n",
       "08/15/2016 20:50:00   NaN\n",
       "08/15/2016 21:05:00   NaN\n",
       "08/15/2016 21:35:00   NaN\n",
       "Name: 905II259BI.PV, Length: 10216, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_nan[df2_with_nan[Sensor].isnull()][Sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1-200TI727HA.PV</th>\n",
       "      <th>A1-200TI727HB.PV</th>\n",
       "      <th>905II259BI.PV</th>\n",
       "      <th>905II259B.CPV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.275757</td>\n",
       "      <td>274.144348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269.463562</td>\n",
       "      <td>272.959808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261.220886</td>\n",
       "      <td>253.513641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:15:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.670807</td>\n",
       "      <td>270.455658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2014 00:20:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.699890</td>\n",
       "      <td>269.445831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A1-200TI727HA.PV  A1-200TI727HB.PV  905II259BI.PV  \\\n",
       "DATETIME                                                                 \n",
       "01/01/2014 00:00:00               NaN               NaN     277.275757   \n",
       "01/01/2014 00:05:00               NaN               NaN     269.463562   \n",
       "01/01/2014 00:10:00               NaN               NaN     261.220886   \n",
       "01/01/2014 00:15:00               NaN               NaN     268.670807   \n",
       "01/01/2014 00:20:00               NaN               NaN     276.699890   \n",
       "\n",
       "                     905II259B.CPV  \n",
       "DATETIME                            \n",
       "01/01/2014 00:00:00     274.144348  \n",
       "01/01/2014 00:05:00     272.959808  \n",
       "01/01/2014 00:10:00     253.513641  \n",
       "01/01/2014 00:15:00     270.455658  \n",
       "01/01/2014 00:20:00     269.445831  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_with_nan[df2_with_nan[Sensor].isnull()][Sensor].to_csv(FinalPath + '/result.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3_with_nan = df2_with_nan.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>A1-200TI727HA.PV</th>\n",
       "      <th>A1-200TI727HB.PV</th>\n",
       "      <th>905II259BI.PV</th>\n",
       "      <th>905II259B.CPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2014 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.275757</td>\n",
       "      <td>274.144348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2014 00:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269.463562</td>\n",
       "      <td>272.959808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2014 00:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261.220886</td>\n",
       "      <td>253.513641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2014 00:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.670807</td>\n",
       "      <td>270.455658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2014 00:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.699890</td>\n",
       "      <td>269.445831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATETIME  A1-200TI727HA.PV  A1-200TI727HB.PV  905II259BI.PV  \\\n",
       "0  01/01/2014 00:00:00               NaN               NaN     277.275757   \n",
       "1  01/01/2014 00:05:00               NaN               NaN     269.463562   \n",
       "2  01/01/2014 00:10:00               NaN               NaN     261.220886   \n",
       "3  01/01/2014 00:15:00               NaN               NaN     268.670807   \n",
       "4  01/01/2014 00:20:00               NaN               NaN     276.699890   \n",
       "\n",
       "   905II259B.CPV  \n",
       "0     274.144348  \n",
       "1     272.959808  \n",
       "2     253.513641  \n",
       "3     270.455658  \n",
       "4     269.445831  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_with_nan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>A1-200TI727HA.PV</th>\n",
       "      <th>A1-200TI727HB.PV</th>\n",
       "      <th>905II259BI.PV</th>\n",
       "      <th>905II259B.CPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>02/05/2014 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285.235565</td>\n",
       "      <td>274.915405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34847</th>\n",
       "      <td>02/05/2014 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DATETIME  A1-200TI727HA.PV  A1-200TI727HB.PV  905II259BI.PV  \\\n",
       "10080  02/05/2014 00:00:00               NaN               NaN     285.235565   \n",
       "34847  02/05/2014 00:00:00               NaN               NaN            NaN   \n",
       "\n",
       "       905II259B.CPV  \n",
       "10080     274.915405  \n",
       "34847            NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df3_with_nan[df3_with_nan['DATETIME']=='02/05/2014 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>A1-200TI727HA.PV</th>\n",
       "      <th>A1-200TI727HB.PV</th>\n",
       "      <th>905II259BI.PV</th>\n",
       "      <th>905II259B.CPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>02/05/2014 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285.235565</td>\n",
       "      <td>274.915405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34847</th>\n",
       "      <td>02/05/2014 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DATETIME  A1-200TI727HA.PV  A1-200TI727HB.PV  905II259BI.PV  \\\n",
       "10080  02/05/2014 00:00:00               NaN               NaN     285.235565   \n",
       "34847  02/05/2014 00:00:00               NaN               NaN            NaN   \n",
       "\n",
       "       905II259B.CPV  \n",
       "10080     274.915405  \n",
       "34847            NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_with_nan[df3_with_nan['DATETIME']=='02/05/2014 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATETIME\n",
       "02/16/2014 05:20:00   NaN\n",
       "04/07/2014 17:45:00   NaN\n",
       "04/28/2014 09:55:00   NaN\n",
       "04/28/2014 10:00:00   NaN\n",
       "04/28/2014 10:05:00   NaN\n",
       "04/28/2014 10:10:00   NaN\n",
       "04/28/2014 10:15:00   NaN\n",
       "04/28/2014 10:20:00   NaN\n",
       "04/28/2014 10:25:00   NaN\n",
       "04/28/2014 21:50:00   NaN\n",
       "04/28/2014 21:55:00   NaN\n",
       "04/28/2014 22:00:00   NaN\n",
       "04/28/2014 22:05:00   NaN\n",
       "04/28/2014 22:10:00   NaN\n",
       "04/28/2014 22:15:00   NaN\n",
       "04/28/2014 22:20:00   NaN\n",
       "04/28/2014 22:25:00   NaN\n",
       "04/28/2014 22:30:00   NaN\n",
       "04/28/2014 22:35:00   NaN\n",
       "04/28/2014 22:40:00   NaN\n",
       "04/28/2014 22:45:00   NaN\n",
       "04/28/2014 22:50:00   NaN\n",
       "04/28/2014 22:55:00   NaN\n",
       "04/28/2014 23:00:00   NaN\n",
       "04/28/2014 23:05:00   NaN\n",
       "04/28/2014 23:10:00   NaN\n",
       "04/28/2014 23:15:00   NaN\n",
       "04/28/2014 23:20:00   NaN\n",
       "04/28/2014 23:25:00   NaN\n",
       "04/28/2014 23:30:00   NaN\n",
       "                       ..\n",
       "04/28/2015 00:10:00   NaN\n",
       "04/28/2015 00:15:00   NaN\n",
       "04/28/2015 00:20:00   NaN\n",
       "04/28/2015 00:25:00   NaN\n",
       "04/28/2015 00:30:00   NaN\n",
       "06/13/2015 11:55:00   NaN\n",
       "06/13/2015 12:00:00   NaN\n",
       "06/13/2015 12:05:00   NaN\n",
       "07/07/2015 15:35:00   NaN\n",
       "01/17/2016 15:45:00   NaN\n",
       "08/04/2016 15:05:00   NaN\n",
       "08/04/2016 15:10:00   NaN\n",
       "08/04/2016 15:15:00   NaN\n",
       "08/04/2016 15:20:00   NaN\n",
       "07/30/2016 09:45:00   NaN\n",
       "07/30/2016 09:50:00   NaN\n",
       "07/30/2016 09:55:00   NaN\n",
       "07/30/2016 10:00:00   NaN\n",
       "07/30/2016 10:05:00   NaN\n",
       "07/30/2016 10:10:00   NaN\n",
       "07/30/2016 10:15:00   NaN\n",
       "07/30/2016 10:20:00   NaN\n",
       "08/15/2016 20:25:00   NaN\n",
       "08/15/2016 20:30:00   NaN\n",
       "08/15/2016 20:35:00   NaN\n",
       "08/15/2016 20:40:00   NaN\n",
       "08/15/2016 20:45:00   NaN\n",
       "08/15/2016 20:50:00   NaN\n",
       "08/15/2016 21:05:00   NaN\n",
       "08/15/2016 21:35:00   NaN\n",
       "Name: 905II259BI.PV, Length: 10216, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_with_nan[df2_with_nan[Sensor].isnull()][Sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = df2_with_nan[df2_with_nan[Sensor].isnull()][Sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATETIME\n",
       "02/16/2014 05:20:00   NaN\n",
       "04/07/2014 17:45:00   NaN\n",
       "04/28/2014 09:55:00   NaN\n",
       "04/28/2014 10:00:00   NaN\n",
       "04/28/2014 10:05:00   NaN\n",
       "04/28/2014 10:10:00   NaN\n",
       "04/28/2014 10:15:00   NaN\n",
       "04/28/2014 10:20:00   NaN\n",
       "04/28/2014 10:25:00   NaN\n",
       "04/28/2014 21:50:00   NaN\n",
       "04/28/2014 21:55:00   NaN\n",
       "04/28/2014 22:00:00   NaN\n",
       "04/28/2014 22:05:00   NaN\n",
       "04/28/2014 22:10:00   NaN\n",
       "04/28/2014 22:15:00   NaN\n",
       "04/28/2014 22:20:00   NaN\n",
       "04/28/2014 22:25:00   NaN\n",
       "04/28/2014 22:30:00   NaN\n",
       "04/28/2014 22:35:00   NaN\n",
       "04/28/2014 22:40:00   NaN\n",
       "04/28/2014 22:45:00   NaN\n",
       "04/28/2014 22:50:00   NaN\n",
       "04/28/2014 22:55:00   NaN\n",
       "04/28/2014 23:00:00   NaN\n",
       "04/28/2014 23:05:00   NaN\n",
       "04/28/2014 23:10:00   NaN\n",
       "04/28/2014 23:15:00   NaN\n",
       "04/28/2014 23:20:00   NaN\n",
       "04/28/2014 23:25:00   NaN\n",
       "04/28/2014 23:30:00   NaN\n",
       "                       ..\n",
       "04/28/2015 00:10:00   NaN\n",
       "04/28/2015 00:15:00   NaN\n",
       "04/28/2015 00:20:00   NaN\n",
       "04/28/2015 00:25:00   NaN\n",
       "04/28/2015 00:30:00   NaN\n",
       "06/13/2015 11:55:00   NaN\n",
       "06/13/2015 12:00:00   NaN\n",
       "06/13/2015 12:05:00   NaN\n",
       "07/07/2015 15:35:00   NaN\n",
       "01/17/2016 15:45:00   NaN\n",
       "08/04/2016 15:05:00   NaN\n",
       "08/04/2016 15:10:00   NaN\n",
       "08/04/2016 15:15:00   NaN\n",
       "08/04/2016 15:20:00   NaN\n",
       "07/30/2016 09:45:00   NaN\n",
       "07/30/2016 09:50:00   NaN\n",
       "07/30/2016 09:55:00   NaN\n",
       "07/30/2016 10:00:00   NaN\n",
       "07/30/2016 10:05:00   NaN\n",
       "07/30/2016 10:10:00   NaN\n",
       "07/30/2016 10:15:00   NaN\n",
       "07/30/2016 10:20:00   NaN\n",
       "08/15/2016 20:25:00   NaN\n",
       "08/15/2016 20:30:00   NaN\n",
       "08/15/2016 20:35:00   NaN\n",
       "08/15/2016 20:40:00   NaN\n",
       "08/15/2016 20:45:00   NaN\n",
       "08/15/2016 20:50:00   NaN\n",
       "08/15/2016 21:05:00   NaN\n",
       "08/15/2016 21:35:00   NaN\n",
       "Name: 905II259BI.PV, Length: 10216, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10216 entries, 02/16/2014 05:20:00 to 08/15/2016 21:35:00\n",
      "Data columns (total 1 columns):\n",
      "905II259BI.PV    0 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 479.6+ KB\n"
     ]
    }
   ],
   "source": [
    "result_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>905II259BI.PV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>08/15/2016 20:40:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08/15/2016 20:45:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08/15/2016 20:50:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08/15/2016 21:05:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08/15/2016 21:35:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     905II259BI.PV\n",
       "DATETIME                          \n",
       "08/15/2016 20:40:00            NaN\n",
       "08/15/2016 20:45:00            NaN\n",
       "08/15/2016 20:50:00            NaN\n",
       "08/15/2016 21:05:00            NaN\n",
       "08/15/2016 21:35:00            NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df = result_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>905II259BI.PV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>08/15/2016 20:40:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10212</th>\n",
       "      <td>08/15/2016 20:45:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10213</th>\n",
       "      <td>08/15/2016 20:50:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10214</th>\n",
       "      <td>08/15/2016 21:05:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10215</th>\n",
       "      <td>08/15/2016 21:35:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DATETIME  905II259BI.PV\n",
       "10211  08/15/2016 20:40:00            NaN\n",
       "10212  08/15/2016 20:45:00            NaN\n",
       "10213  08/15/2016 20:50:00            NaN\n",
       "10214  08/15/2016 21:05:00            NaN\n",
       "10215  08/15/2016 21:35:00            NaN"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df['DATETIME'].to_csv(FinalPath + '/result_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271551    Bad\n",
       "Name: 905II259BI.PV, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2[df2_2['DATETIME']=='08/15/2016 21:35:00'][Sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_2.loc[:, Sensor]\n",
    "# df2.loc[\"Alaska\":\"Arkansas\",\"2005\":\"2007\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02/16/2014 05:20:00',\n",
       " '04/07/2014 17:45:00',\n",
       " '04/28/2014 09:55:00',\n",
       " '04/28/2014 10:00:00',\n",
       " '04/28/2014 10:05:00',\n",
       " '04/28/2014 10:10:00',\n",
       " '04/28/2014 10:15:00',\n",
       " '04/28/2014 10:20:00',\n",
       " '04/28/2014 10:25:00',\n",
       " '04/28/2014 21:50:00',\n",
       " '04/28/2014 21:55:00',\n",
       " '04/28/2014 22:00:00',\n",
       " '04/28/2014 22:05:00',\n",
       " '04/28/2014 22:10:00',\n",
       " '04/28/2014 22:15:00',\n",
       " '04/28/2014 22:20:00',\n",
       " '04/28/2014 22:25:00',\n",
       " '04/28/2014 22:30:00',\n",
       " '04/28/2014 22:35:00',\n",
       " '04/28/2014 22:40:00',\n",
       " '04/28/2014 22:45:00',\n",
       " '04/28/2014 22:50:00',\n",
       " '04/28/2014 22:55:00',\n",
       " '04/28/2014 23:00:00',\n",
       " '04/28/2014 23:05:00',\n",
       " '04/28/2014 23:10:00',\n",
       " '04/28/2014 23:15:00',\n",
       " '04/28/2014 23:20:00',\n",
       " '04/28/2014 23:25:00',\n",
       " '04/28/2014 23:30:00',\n",
       " '04/28/2014 23:35:00',\n",
       " '04/28/2014 23:40:00',\n",
       " '04/28/2014 23:45:00',\n",
       " '04/28/2014 23:50:00',\n",
       " '04/28/2014 23:55:00',\n",
       " '04/29/2014 00:00:00',\n",
       " '04/29/2014 00:05:00',\n",
       " '04/29/2014 00:10:00',\n",
       " '04/29/2014 00:15:00',\n",
       " '04/29/2014 00:20:00',\n",
       " '04/29/2014 00:25:00',\n",
       " '04/29/2014 00:30:00',\n",
       " '04/29/2014 00:35:00',\n",
       " '04/29/2014 00:40:00',\n",
       " '04/29/2014 00:45:00',\n",
       " '04/29/2014 00:50:00',\n",
       " '04/29/2014 00:55:00',\n",
       " '04/29/2014 01:00:00',\n",
       " '04/29/2014 01:05:00',\n",
       " '04/29/2014 01:10:00',\n",
       " '04/29/2014 01:15:00',\n",
       " '04/29/2014 01:20:00',\n",
       " '04/29/2014 01:25:00',\n",
       " '04/29/2014 01:30:00',\n",
       " '04/29/2014 01:35:00',\n",
       " '04/29/2014 01:40:00',\n",
       " '04/29/2014 01:45:00',\n",
       " '04/29/2014 01:50:00',\n",
       " '04/29/2014 01:55:00',\n",
       " '04/29/2014 02:00:00',\n",
       " '04/29/2014 02:05:00',\n",
       " '04/29/2014 02:10:00',\n",
       " '04/29/2014 02:15:00',\n",
       " '04/29/2014 02:20:00',\n",
       " '04/29/2014 02:25:00',\n",
       " '04/29/2014 02:30:00',\n",
       " '04/29/2014 02:35:00',\n",
       " '04/29/2014 02:40:00',\n",
       " '04/29/2014 02:45:00',\n",
       " '04/29/2014 02:50:00',\n",
       " '04/29/2014 02:55:00',\n",
       " '04/29/2014 03:00:00',\n",
       " '04/29/2014 03:05:00',\n",
       " '04/29/2014 03:10:00',\n",
       " '04/29/2014 03:15:00',\n",
       " '04/29/2014 03:20:00',\n",
       " '04/29/2014 03:25:00',\n",
       " '04/29/2014 03:30:00',\n",
       " '04/29/2014 03:35:00',\n",
       " '04/29/2014 03:40:00',\n",
       " '04/29/2014 03:45:00',\n",
       " '04/29/2014 03:50:00',\n",
       " '04/29/2014 03:55:00',\n",
       " '04/29/2014 04:00:00',\n",
       " '04/29/2014 04:05:00',\n",
       " '04/29/2014 04:10:00',\n",
       " '04/29/2014 04:15:00',\n",
       " '04/29/2014 04:20:00',\n",
       " '04/29/2014 04:25:00',\n",
       " '04/29/2014 04:30:00',\n",
       " '04/29/2014 04:35:00',\n",
       " '04/29/2014 04:40:00',\n",
       " '04/29/2014 04:45:00',\n",
       " '04/29/2014 04:50:00',\n",
       " '04/29/2014 04:55:00',\n",
       " '04/29/2014 05:00:00',\n",
       " '04/29/2014 05:05:00',\n",
       " '04/29/2014 05:10:00',\n",
       " '04/29/2014 05:15:00',\n",
       " '04/29/2014 05:20:00',\n",
       " '04/29/2014 05:25:00',\n",
       " '04/29/2014 05:30:00',\n",
       " '04/29/2014 05:35:00',\n",
       " '04/29/2014 05:40:00',\n",
       " '04/29/2014 05:45:00',\n",
       " '04/29/2014 05:50:00',\n",
       " '04/29/2014 05:55:00',\n",
       " '04/29/2014 06:00:00',\n",
       " '04/29/2014 06:05:00',\n",
       " '04/29/2014 06:10:00',\n",
       " '04/29/2014 06:15:00',\n",
       " '04/29/2014 06:20:00',\n",
       " '04/29/2014 06:25:00',\n",
       " '04/29/2014 06:30:00',\n",
       " '04/29/2014 06:35:00',\n",
       " '04/29/2014 06:40:00',\n",
       " '04/29/2014 06:45:00',\n",
       " '04/29/2014 06:50:00',\n",
       " '04/29/2014 06:55:00',\n",
       " '04/29/2014 07:00:00',\n",
       " '04/29/2014 07:05:00',\n",
       " '04/29/2014 07:10:00',\n",
       " '04/29/2014 07:15:00',\n",
       " '04/29/2014 07:20:00',\n",
       " '04/29/2014 07:25:00',\n",
       " '04/29/2014 07:30:00',\n",
       " '04/29/2014 07:35:00',\n",
       " '04/29/2014 07:40:00',\n",
       " '04/29/2014 07:45:00',\n",
       " '04/29/2014 07:50:00',\n",
       " '04/29/2014 07:55:00',\n",
       " '04/29/2014 08:00:00',\n",
       " '04/29/2014 08:05:00',\n",
       " '04/29/2014 08:10:00',\n",
       " '04/29/2014 08:15:00',\n",
       " '04/29/2014 08:20:00',\n",
       " '04/29/2014 08:25:00',\n",
       " '04/29/2014 08:30:00',\n",
       " '04/29/2014 08:35:00',\n",
       " '04/29/2014 08:40:00',\n",
       " '04/29/2014 08:45:00',\n",
       " '04/29/2014 08:50:00',\n",
       " '04/29/2014 08:55:00',\n",
       " '04/29/2014 09:00:00',\n",
       " '04/29/2014 09:05:00',\n",
       " '04/29/2014 09:10:00',\n",
       " '04/29/2014 09:15:00',\n",
       " '04/29/2014 09:20:00',\n",
       " '04/29/2014 09:25:00',\n",
       " '04/29/2014 09:30:00',\n",
       " '04/29/2014 09:35:00',\n",
       " '04/29/2014 09:40:00',\n",
       " '04/29/2014 09:45:00',\n",
       " '04/29/2014 09:50:00',\n",
       " '04/29/2014 09:55:00',\n",
       " '04/29/2014 10:00:00',\n",
       " '04/29/2014 10:05:00',\n",
       " '04/29/2014 10:10:00',\n",
       " '04/29/2014 10:15:00',\n",
       " '04/29/2014 10:20:00',\n",
       " '04/29/2014 10:25:00',\n",
       " '04/29/2014 10:30:00',\n",
       " '04/29/2014 10:35:00',\n",
       " '04/29/2014 10:40:00',\n",
       " '04/29/2014 10:45:00',\n",
       " '04/29/2014 10:50:00',\n",
       " '04/29/2014 10:55:00',\n",
       " '04/29/2014 11:00:00',\n",
       " '04/29/2014 11:05:00',\n",
       " '04/29/2014 11:10:00',\n",
       " '04/29/2014 11:15:00',\n",
       " '04/29/2014 11:20:00',\n",
       " '04/29/2014 11:25:00',\n",
       " '04/29/2014 11:30:00',\n",
       " '04/29/2014 11:35:00',\n",
       " '04/29/2014 11:40:00',\n",
       " '04/29/2014 11:45:00',\n",
       " '04/29/2014 11:50:00',\n",
       " '04/29/2014 11:55:00',\n",
       " '04/29/2014 12:00:00',\n",
       " '04/29/2014 12:05:00',\n",
       " '04/29/2014 12:10:00',\n",
       " '04/29/2014 12:15:00',\n",
       " '04/29/2014 12:20:00',\n",
       " '04/29/2014 12:25:00',\n",
       " '04/29/2014 12:30:00',\n",
       " '04/29/2014 12:35:00',\n",
       " '04/29/2014 12:40:00',\n",
       " '04/29/2014 12:45:00',\n",
       " '04/29/2014 12:50:00',\n",
       " '04/29/2014 12:55:00',\n",
       " '04/29/2014 13:00:00',\n",
       " '04/29/2014 13:05:00',\n",
       " '04/29/2014 13:10:00',\n",
       " '04/29/2014 13:15:00',\n",
       " '04/29/2014 13:20:00',\n",
       " '04/29/2014 13:25:00',\n",
       " '04/29/2014 13:30:00',\n",
       " '04/29/2014 13:35:00',\n",
       " '04/29/2014 13:40:00',\n",
       " '04/29/2014 13:45:00',\n",
       " '04/29/2014 13:50:00',\n",
       " '04/29/2014 13:55:00',\n",
       " '04/29/2014 14:00:00',\n",
       " '04/29/2014 14:05:00',\n",
       " '04/29/2014 14:10:00',\n",
       " '04/29/2014 14:15:00',\n",
       " '04/29/2014 14:20:00',\n",
       " '04/29/2014 14:25:00',\n",
       " '04/29/2014 14:30:00',\n",
       " '04/29/2014 14:35:00',\n",
       " '04/29/2014 14:40:00',\n",
       " '04/29/2014 14:45:00',\n",
       " '04/29/2014 14:50:00',\n",
       " '04/29/2014 14:55:00',\n",
       " '04/29/2014 15:00:00',\n",
       " '04/29/2014 15:05:00',\n",
       " '04/29/2014 15:10:00',\n",
       " '04/29/2014 15:15:00',\n",
       " '04/29/2014 15:20:00',\n",
       " '04/29/2014 15:25:00',\n",
       " '04/29/2014 15:30:00',\n",
       " '04/29/2014 15:35:00',\n",
       " '04/29/2014 15:40:00',\n",
       " '04/29/2014 15:45:00',\n",
       " '04/29/2014 15:50:00',\n",
       " '04/29/2014 15:55:00',\n",
       " '04/29/2014 16:00:00',\n",
       " '04/29/2014 16:05:00',\n",
       " '04/29/2014 16:10:00',\n",
       " '04/29/2014 16:15:00',\n",
       " '04/29/2014 16:20:00',\n",
       " '04/29/2014 16:25:00',\n",
       " '04/29/2014 16:30:00',\n",
       " '04/29/2014 16:35:00',\n",
       " '04/29/2014 16:40:00',\n",
       " '04/29/2014 16:45:00',\n",
       " '04/29/2014 16:50:00',\n",
       " '04/29/2014 16:55:00',\n",
       " '04/29/2014 17:00:00',\n",
       " '04/29/2014 17:05:00',\n",
       " '04/29/2014 17:10:00',\n",
       " '04/29/2014 17:15:00',\n",
       " '04/29/2014 17:20:00',\n",
       " '04/29/2014 17:25:00',\n",
       " '04/29/2014 17:30:00',\n",
       " '04/29/2014 17:35:00',\n",
       " '04/29/2014 17:40:00',\n",
       " '04/29/2014 17:45:00',\n",
       " '04/29/2014 17:50:00',\n",
       " '04/29/2014 17:55:00',\n",
       " '04/29/2014 18:00:00',\n",
       " '04/29/2014 18:05:00',\n",
       " '04/29/2014 18:10:00',\n",
       " '04/29/2014 18:15:00',\n",
       " '04/29/2014 18:20:00',\n",
       " '04/29/2014 18:25:00',\n",
       " '04/29/2014 18:30:00',\n",
       " '04/29/2014 18:35:00',\n",
       " '04/29/2014 18:40:00',\n",
       " '04/29/2014 18:45:00',\n",
       " '04/29/2014 18:50:00',\n",
       " '04/29/2014 18:55:00',\n",
       " '04/29/2014 19:00:00',\n",
       " '04/29/2014 19:05:00',\n",
       " '04/29/2014 19:10:00',\n",
       " '04/29/2014 19:15:00',\n",
       " '04/29/2014 19:20:00',\n",
       " '04/29/2014 19:25:00',\n",
       " '04/29/2014 19:30:00',\n",
       " '04/29/2014 19:35:00',\n",
       " '04/29/2014 19:40:00',\n",
       " '04/29/2014 19:45:00',\n",
       " '04/29/2014 19:50:00',\n",
       " '04/29/2014 19:55:00',\n",
       " '04/29/2014 20:00:00',\n",
       " '04/29/2014 20:05:00',\n",
       " '04/29/2014 20:10:00',\n",
       " '04/29/2014 20:15:00',\n",
       " '04/29/2014 20:20:00',\n",
       " '04/29/2014 20:25:00',\n",
       " '04/29/2014 20:30:00',\n",
       " '04/29/2014 20:35:00',\n",
       " '04/29/2014 20:40:00',\n",
       " '04/29/2014 20:45:00',\n",
       " '04/29/2014 20:50:00',\n",
       " '04/29/2014 20:55:00',\n",
       " '04/29/2014 21:00:00',\n",
       " '04/29/2014 21:05:00',\n",
       " '04/29/2014 21:10:00',\n",
       " '04/29/2014 21:15:00',\n",
       " '04/29/2014 21:20:00',\n",
       " '04/29/2014 21:25:00',\n",
       " '04/29/2014 21:30:00',\n",
       " '04/29/2014 21:35:00',\n",
       " '04/29/2014 21:40:00',\n",
       " '04/29/2014 21:45:00',\n",
       " '04/29/2014 21:50:00',\n",
       " '04/29/2014 21:55:00',\n",
       " '04/29/2014 22:00:00',\n",
       " '04/29/2014 22:05:00',\n",
       " '04/29/2014 22:10:00',\n",
       " '04/29/2014 22:15:00',\n",
       " '04/29/2014 22:20:00',\n",
       " '04/29/2014 22:25:00',\n",
       " '04/29/2014 22:30:00',\n",
       " '04/29/2014 22:35:00',\n",
       " '04/29/2014 22:40:00',\n",
       " '04/29/2014 22:45:00',\n",
       " '04/29/2014 22:50:00',\n",
       " '04/29/2014 22:55:00',\n",
       " '04/29/2014 23:00:00',\n",
       " '04/29/2014 23:05:00',\n",
       " '04/29/2014 23:10:00',\n",
       " '04/29/2014 23:15:00',\n",
       " '04/29/2014 23:20:00',\n",
       " '04/29/2014 23:25:00',\n",
       " '04/29/2014 23:30:00',\n",
       " '04/29/2014 23:35:00',\n",
       " '04/29/2014 23:40:00',\n",
       " '04/29/2014 23:45:00',\n",
       " '04/29/2014 23:50:00',\n",
       " '04/29/2014 23:55:00',\n",
       " '04/30/2014 00:00:00',\n",
       " '04/30/2014 00:05:00',\n",
       " '04/30/2014 00:10:00',\n",
       " '04/30/2014 00:15:00',\n",
       " '04/30/2014 00:20:00',\n",
       " '04/30/2014 00:25:00',\n",
       " '04/30/2014 00:30:00',\n",
       " '04/30/2014 00:35:00',\n",
       " '04/30/2014 00:40:00',\n",
       " '04/30/2014 00:45:00',\n",
       " '04/30/2014 00:50:00',\n",
       " '04/30/2014 00:55:00',\n",
       " '04/30/2014 01:00:00',\n",
       " '04/30/2014 01:05:00',\n",
       " '04/30/2014 01:10:00',\n",
       " '04/30/2014 01:15:00',\n",
       " '04/30/2014 01:20:00',\n",
       " '04/30/2014 01:25:00',\n",
       " '04/30/2014 01:30:00',\n",
       " '04/30/2014 01:35:00',\n",
       " '04/30/2014 01:40:00',\n",
       " '04/30/2014 01:45:00',\n",
       " '04/30/2014 01:50:00',\n",
       " '04/30/2014 01:55:00',\n",
       " '04/30/2014 02:00:00',\n",
       " '04/30/2014 02:05:00',\n",
       " '04/30/2014 02:10:00',\n",
       " '04/30/2014 02:15:00',\n",
       " '04/30/2014 02:20:00',\n",
       " '04/30/2014 02:25:00',\n",
       " '04/30/2014 02:30:00',\n",
       " '04/30/2014 02:35:00',\n",
       " '04/30/2014 02:40:00',\n",
       " '04/30/2014 02:45:00',\n",
       " '04/30/2014 02:50:00',\n",
       " '04/30/2014 02:55:00',\n",
       " '04/30/2014 03:00:00',\n",
       " '04/30/2014 03:05:00',\n",
       " '04/30/2014 03:10:00',\n",
       " '04/30/2014 03:15:00',\n",
       " '04/30/2014 03:20:00',\n",
       " '04/30/2014 03:25:00',\n",
       " '04/30/2014 03:30:00',\n",
       " '04/30/2014 03:35:00',\n",
       " '04/30/2014 03:40:00',\n",
       " '04/30/2014 03:45:00',\n",
       " '04/30/2014 03:50:00',\n",
       " '04/30/2014 03:55:00',\n",
       " '04/30/2014 04:00:00',\n",
       " '04/30/2014 04:05:00',\n",
       " '04/30/2014 04:10:00',\n",
       " '04/30/2014 04:15:00',\n",
       " '04/30/2014 04:20:00',\n",
       " '04/30/2014 04:25:00',\n",
       " '04/30/2014 04:30:00',\n",
       " '04/30/2014 04:35:00',\n",
       " '04/30/2014 04:40:00',\n",
       " '04/30/2014 04:45:00',\n",
       " '04/30/2014 04:50:00',\n",
       " '04/30/2014 04:55:00',\n",
       " '04/30/2014 05:00:00',\n",
       " '04/30/2014 05:05:00',\n",
       " '04/30/2014 05:10:00',\n",
       " '04/30/2014 05:15:00',\n",
       " '04/30/2014 05:20:00',\n",
       " '04/30/2014 05:25:00',\n",
       " '04/30/2014 05:30:00',\n",
       " '04/30/2014 05:35:00',\n",
       " '04/30/2014 05:40:00',\n",
       " '04/30/2014 05:45:00',\n",
       " '04/30/2014 05:50:00',\n",
       " '04/30/2014 05:55:00',\n",
       " '04/30/2014 06:00:00',\n",
       " '04/30/2014 06:05:00',\n",
       " '04/30/2014 06:10:00',\n",
       " '04/30/2014 06:15:00',\n",
       " '04/30/2014 06:20:00',\n",
       " '04/30/2014 06:25:00',\n",
       " '04/30/2014 06:30:00',\n",
       " '04/30/2014 06:35:00',\n",
       " '04/30/2014 06:40:00',\n",
       " '04/30/2014 06:45:00',\n",
       " '04/30/2014 06:50:00',\n",
       " '04/30/2014 06:55:00',\n",
       " '04/30/2014 07:00:00',\n",
       " '04/30/2014 07:05:00',\n",
       " '04/30/2014 07:10:00',\n",
       " '04/30/2014 07:15:00',\n",
       " '04/30/2014 07:20:00',\n",
       " '04/30/2014 07:25:00',\n",
       " '04/30/2014 07:30:00',\n",
       " '04/30/2014 07:35:00',\n",
       " '04/30/2014 07:40:00',\n",
       " '04/30/2014 07:45:00',\n",
       " '04/30/2014 07:50:00',\n",
       " '04/30/2014 07:55:00',\n",
       " '04/30/2014 08:00:00',\n",
       " '04/30/2014 08:05:00',\n",
       " '04/30/2014 08:10:00',\n",
       " '04/30/2014 08:15:00',\n",
       " '04/30/2014 08:20:00',\n",
       " '04/30/2014 08:25:00',\n",
       " '04/30/2014 08:30:00',\n",
       " '04/30/2014 08:35:00',\n",
       " '04/30/2014 08:40:00',\n",
       " '04/30/2014 08:45:00',\n",
       " '04/30/2014 08:50:00',\n",
       " '04/30/2014 08:55:00',\n",
       " '04/30/2014 09:00:00',\n",
       " '04/30/2014 09:05:00',\n",
       " '04/30/2014 09:10:00',\n",
       " '04/30/2014 09:15:00',\n",
       " '04/30/2014 09:20:00',\n",
       " '04/30/2014 09:25:00',\n",
       " '04/30/2014 09:30:00',\n",
       " '04/30/2014 09:35:00',\n",
       " '04/30/2014 09:40:00',\n",
       " '04/30/2014 09:45:00',\n",
       " '04/30/2014 09:50:00',\n",
       " '04/30/2014 09:55:00',\n",
       " '04/30/2014 10:00:00',\n",
       " '04/30/2014 10:05:00',\n",
       " '04/30/2014 10:10:00',\n",
       " '04/30/2014 10:15:00',\n",
       " '04/30/2014 10:20:00',\n",
       " '04/30/2014 10:25:00',\n",
       " '04/30/2014 10:30:00',\n",
       " '04/30/2014 10:35:00',\n",
       " '04/30/2014 10:40:00',\n",
       " '04/30/2014 10:45:00',\n",
       " '04/30/2014 10:50:00',\n",
       " '04/30/2014 10:55:00',\n",
       " '04/30/2014 11:00:00',\n",
       " '04/30/2014 11:05:00',\n",
       " '04/30/2014 11:10:00',\n",
       " '04/30/2014 11:15:00',\n",
       " '04/30/2014 11:20:00',\n",
       " '04/30/2014 11:25:00',\n",
       " '04/30/2014 11:30:00',\n",
       " '04/30/2014 11:35:00',\n",
       " '04/30/2014 11:40:00',\n",
       " '04/30/2014 11:45:00',\n",
       " '04/30/2014 11:50:00',\n",
       " '04/30/2014 11:55:00',\n",
       " '04/30/2014 12:00:00',\n",
       " '04/30/2014 12:05:00',\n",
       " '04/30/2014 12:10:00',\n",
       " '04/30/2014 12:15:00',\n",
       " '04/30/2014 12:20:00',\n",
       " '04/30/2014 12:25:00',\n",
       " '04/30/2014 12:30:00',\n",
       " '04/30/2014 12:35:00',\n",
       " '04/30/2014 12:40:00',\n",
       " '04/30/2014 12:45:00',\n",
       " '04/30/2014 12:50:00',\n",
       " '04/30/2014 12:55:00',\n",
       " '04/30/2014 13:00:00',\n",
       " '04/30/2014 13:05:00',\n",
       " '04/30/2014 13:10:00',\n",
       " '04/30/2014 13:15:00',\n",
       " '04/30/2014 13:20:00',\n",
       " '04/30/2014 13:25:00',\n",
       " '04/30/2014 13:30:00',\n",
       " '04/30/2014 13:35:00',\n",
       " '04/30/2014 13:40:00',\n",
       " '04/30/2014 13:45:00',\n",
       " '04/30/2014 13:50:00',\n",
       " '04/30/2014 13:55:00',\n",
       " '04/30/2014 14:00:00',\n",
       " '04/30/2014 14:05:00',\n",
       " '04/30/2014 14:10:00',\n",
       " '04/30/2014 14:15:00',\n",
       " '04/30/2014 14:20:00',\n",
       " '04/30/2014 14:25:00',\n",
       " '04/30/2014 14:30:00',\n",
       " '04/30/2014 14:35:00',\n",
       " '04/30/2014 14:40:00',\n",
       " '04/30/2014 14:45:00',\n",
       " '04/30/2014 14:50:00',\n",
       " '04/30/2014 14:55:00',\n",
       " '04/30/2014 15:00:00',\n",
       " '04/30/2014 15:05:00',\n",
       " '04/30/2014 15:10:00',\n",
       " '04/30/2014 15:15:00',\n",
       " '04/30/2014 15:20:00',\n",
       " '04/30/2014 15:25:00',\n",
       " '04/30/2014 15:30:00',\n",
       " '04/30/2014 15:35:00',\n",
       " '04/30/2014 15:40:00',\n",
       " '04/30/2014 15:45:00',\n",
       " '04/30/2014 15:50:00',\n",
       " '04/30/2014 15:55:00',\n",
       " '04/30/2014 16:00:00',\n",
       " '04/30/2014 16:05:00',\n",
       " '04/30/2014 16:10:00',\n",
       " '04/30/2014 16:15:00',\n",
       " '04/30/2014 16:20:00',\n",
       " '04/30/2014 16:25:00',\n",
       " '04/30/2014 16:30:00',\n",
       " '04/30/2014 16:35:00',\n",
       " '04/30/2014 16:40:00',\n",
       " '04/30/2014 16:45:00',\n",
       " '04/30/2014 16:50:00',\n",
       " '04/30/2014 16:55:00',\n",
       " '04/30/2014 17:00:00',\n",
       " '04/30/2014 17:05:00',\n",
       " '04/30/2014 17:10:00',\n",
       " '04/30/2014 17:15:00',\n",
       " '04/30/2014 17:20:00',\n",
       " '04/30/2014 17:25:00',\n",
       " '04/30/2014 17:30:00',\n",
       " '04/30/2014 17:35:00',\n",
       " '04/30/2014 17:40:00',\n",
       " '04/30/2014 17:45:00',\n",
       " '04/30/2014 17:50:00',\n",
       " '04/30/2014 17:55:00',\n",
       " '04/30/2014 18:00:00',\n",
       " '04/30/2014 18:05:00',\n",
       " '04/30/2014 18:10:00',\n",
       " '04/30/2014 18:15:00',\n",
       " '04/30/2014 18:20:00',\n",
       " '04/30/2014 18:25:00',\n",
       " '04/30/2014 18:30:00',\n",
       " '04/30/2014 18:35:00',\n",
       " '04/30/2014 18:40:00',\n",
       " '04/30/2014 18:45:00',\n",
       " '04/30/2014 18:50:00',\n",
       " '04/30/2014 18:55:00',\n",
       " '04/30/2014 19:00:00',\n",
       " '04/30/2014 19:05:00',\n",
       " '04/30/2014 19:10:00',\n",
       " '04/30/2014 19:15:00',\n",
       " '04/30/2014 19:20:00',\n",
       " '04/30/2014 19:25:00',\n",
       " '04/30/2014 19:30:00',\n",
       " '04/30/2014 19:35:00',\n",
       " '04/30/2014 19:40:00',\n",
       " '04/30/2014 19:45:00',\n",
       " '04/30/2014 19:50:00',\n",
       " '04/30/2014 19:55:00',\n",
       " '04/30/2014 20:00:00',\n",
       " '04/30/2014 20:05:00',\n",
       " '04/30/2014 20:10:00',\n",
       " '04/30/2014 20:15:00',\n",
       " '04/30/2014 20:20:00',\n",
       " '04/30/2014 20:25:00',\n",
       " '04/30/2014 20:30:00',\n",
       " '04/30/2014 20:35:00',\n",
       " '04/30/2014 20:40:00',\n",
       " '04/30/2014 20:45:00',\n",
       " '04/30/2014 20:50:00',\n",
       " '04/30/2014 20:55:00',\n",
       " '04/30/2014 21:00:00',\n",
       " '04/30/2014 21:05:00',\n",
       " '04/30/2014 21:10:00',\n",
       " '04/30/2014 21:15:00',\n",
       " '04/30/2014 21:20:00',\n",
       " '04/30/2014 21:25:00',\n",
       " '04/30/2014 21:30:00',\n",
       " '04/30/2014 21:35:00',\n",
       " '04/30/2014 21:40:00',\n",
       " '04/30/2014 21:45:00',\n",
       " '04/30/2014 21:50:00',\n",
       " '04/30/2014 21:55:00',\n",
       " '04/30/2014 22:00:00',\n",
       " '04/30/2014 22:05:00',\n",
       " '04/30/2014 22:10:00',\n",
       " '04/30/2014 22:15:00',\n",
       " '04/30/2014 22:20:00',\n",
       " '04/30/2014 22:25:00',\n",
       " '04/30/2014 22:30:00',\n",
       " '04/30/2014 22:35:00',\n",
       " '04/30/2014 22:40:00',\n",
       " '04/30/2014 22:45:00',\n",
       " '04/30/2014 22:50:00',\n",
       " '04/30/2014 22:55:00',\n",
       " '04/30/2014 23:00:00',\n",
       " '04/30/2014 23:05:00',\n",
       " '04/30/2014 23:10:00',\n",
       " '04/30/2014 23:15:00',\n",
       " '04/30/2014 23:20:00',\n",
       " '04/30/2014 23:25:00',\n",
       " '04/30/2014 23:30:00',\n",
       " '04/30/2014 23:35:00',\n",
       " '04/30/2014 23:40:00',\n",
       " '04/30/2014 23:45:00',\n",
       " '04/30/2014 23:50:00',\n",
       " '04/30/2014 23:55:00',\n",
       " '01/05/2014 00:05:00',\n",
       " '01/05/2014 00:10:00',\n",
       " '01/05/2014 00:15:00',\n",
       " '01/05/2014 00:20:00',\n",
       " '01/05/2014 00:25:00',\n",
       " '01/05/2014 00:30:00',\n",
       " '01/05/2014 00:35:00',\n",
       " '01/05/2014 00:40:00',\n",
       " '01/05/2014 00:45:00',\n",
       " '01/05/2014 00:50:00',\n",
       " '01/05/2014 00:55:00',\n",
       " '01/05/2014 01:00:00',\n",
       " '01/05/2014 01:05:00',\n",
       " '01/05/2014 01:10:00',\n",
       " '01/05/2014 01:15:00',\n",
       " '01/05/2014 01:20:00',\n",
       " '01/05/2014 01:25:00',\n",
       " '01/05/2014 01:30:00',\n",
       " '01/05/2014 01:35:00',\n",
       " '01/05/2014 01:40:00',\n",
       " '01/05/2014 01:45:00',\n",
       " '01/05/2014 01:50:00',\n",
       " '01/05/2014 01:55:00',\n",
       " '01/05/2014 02:00:00',\n",
       " '01/05/2014 02:05:00',\n",
       " '01/05/2014 02:10:00',\n",
       " '01/05/2014 02:15:00',\n",
       " '01/05/2014 02:20:00',\n",
       " '01/05/2014 02:25:00',\n",
       " '01/05/2014 02:30:00',\n",
       " '01/05/2014 02:35:00',\n",
       " '01/05/2014 02:40:00',\n",
       " '01/05/2014 02:45:00',\n",
       " '01/05/2014 02:50:00',\n",
       " '01/05/2014 02:55:00',\n",
       " '01/05/2014 03:00:00',\n",
       " '01/05/2014 03:05:00',\n",
       " '01/05/2014 03:10:00',\n",
       " '01/05/2014 03:15:00',\n",
       " '01/05/2014 03:20:00',\n",
       " '01/05/2014 03:25:00',\n",
       " '01/05/2014 03:30:00',\n",
       " '01/05/2014 03:35:00',\n",
       " '01/05/2014 03:40:00',\n",
       " '01/05/2014 03:45:00',\n",
       " '01/05/2014 03:50:00',\n",
       " '01/05/2014 03:55:00',\n",
       " '01/05/2014 04:00:00',\n",
       " '01/05/2014 04:05:00',\n",
       " '01/05/2014 04:10:00',\n",
       " '01/05/2014 04:15:00',\n",
       " '01/05/2014 04:20:00',\n",
       " '01/05/2014 04:25:00',\n",
       " '01/05/2014 04:30:00',\n",
       " '01/05/2014 04:35:00',\n",
       " '01/05/2014 04:40:00',\n",
       " '01/05/2014 04:45:00',\n",
       " '01/05/2014 04:50:00',\n",
       " '01/05/2014 04:55:00',\n",
       " '01/05/2014 05:00:00',\n",
       " '01/05/2014 05:05:00',\n",
       " '01/05/2014 05:10:00',\n",
       " '01/05/2014 05:15:00',\n",
       " '01/05/2014 05:20:00',\n",
       " '01/05/2014 05:25:00',\n",
       " '01/05/2014 05:30:00',\n",
       " '01/05/2014 05:35:00',\n",
       " '01/05/2014 05:40:00',\n",
       " '01/05/2014 05:45:00',\n",
       " '01/05/2014 05:50:00',\n",
       " '01/05/2014 05:55:00',\n",
       " '01/05/2014 06:00:00',\n",
       " '01/05/2014 06:05:00',\n",
       " '01/05/2014 06:10:00',\n",
       " '01/05/2014 06:15:00',\n",
       " '01/05/2014 06:20:00',\n",
       " '01/05/2014 06:25:00',\n",
       " '01/05/2014 06:30:00',\n",
       " '01/05/2014 06:35:00',\n",
       " '01/05/2014 06:40:00',\n",
       " '01/05/2014 06:45:00',\n",
       " '01/05/2014 06:50:00',\n",
       " '01/05/2014 06:55:00',\n",
       " '01/05/2014 07:00:00',\n",
       " '01/05/2014 07:05:00',\n",
       " '01/05/2014 07:10:00',\n",
       " '01/05/2014 07:15:00',\n",
       " '01/05/2014 07:20:00',\n",
       " '01/05/2014 07:25:00',\n",
       " '01/05/2014 07:30:00',\n",
       " '01/05/2014 07:35:00',\n",
       " '01/05/2014 07:40:00',\n",
       " '01/05/2014 07:45:00',\n",
       " '01/05/2014 07:50:00',\n",
       " '01/05/2014 07:55:00',\n",
       " '01/05/2014 08:00:00',\n",
       " '01/05/2014 08:05:00',\n",
       " '01/05/2014 08:10:00',\n",
       " '01/05/2014 08:15:00',\n",
       " '01/05/2014 08:20:00',\n",
       " '01/05/2014 08:25:00',\n",
       " '01/05/2014 08:30:00',\n",
       " '01/05/2014 08:35:00',\n",
       " '01/05/2014 08:40:00',\n",
       " '01/05/2014 08:45:00',\n",
       " '01/05/2014 08:50:00',\n",
       " '01/05/2014 08:55:00',\n",
       " '01/05/2014 09:00:00',\n",
       " '01/05/2014 09:05:00',\n",
       " '01/05/2014 09:10:00',\n",
       " '01/05/2014 09:15:00',\n",
       " '01/05/2014 09:20:00',\n",
       " '01/05/2014 09:25:00',\n",
       " '01/05/2014 09:30:00',\n",
       " '01/05/2014 09:35:00',\n",
       " '01/05/2014 09:40:00',\n",
       " '01/05/2014 09:45:00',\n",
       " '01/05/2014 09:50:00',\n",
       " '01/05/2014 09:55:00',\n",
       " '01/05/2014 10:00:00',\n",
       " '01/05/2014 10:05:00',\n",
       " '01/05/2014 10:10:00',\n",
       " '01/05/2014 10:15:00',\n",
       " '01/05/2014 10:20:00',\n",
       " '01/05/2014 10:25:00',\n",
       " '01/05/2014 10:30:00',\n",
       " '01/05/2014 10:35:00',\n",
       " '01/05/2014 10:40:00',\n",
       " '01/05/2014 10:45:00',\n",
       " '01/05/2014 10:50:00',\n",
       " '01/05/2014 10:55:00',\n",
       " '01/05/2014 11:00:00',\n",
       " '01/05/2014 11:05:00',\n",
       " '01/05/2014 11:10:00',\n",
       " '01/05/2014 11:15:00',\n",
       " '01/05/2014 11:20:00',\n",
       " '01/05/2014 11:25:00',\n",
       " '01/05/2014 11:30:00',\n",
       " '01/05/2014 11:35:00',\n",
       " '01/05/2014 11:40:00',\n",
       " '01/05/2014 11:45:00',\n",
       " '01/05/2014 11:50:00',\n",
       " '01/05/2014 11:55:00',\n",
       " '01/05/2014 12:00:00',\n",
       " '01/05/2014 12:05:00',\n",
       " '01/05/2014 12:10:00',\n",
       " '01/05/2014 12:15:00',\n",
       " '01/05/2014 12:20:00',\n",
       " '01/05/2014 12:25:00',\n",
       " '01/05/2014 12:30:00',\n",
       " '01/05/2014 12:35:00',\n",
       " '01/05/2014 12:40:00',\n",
       " '01/05/2014 12:45:00',\n",
       " '01/05/2014 12:50:00',\n",
       " '01/05/2014 12:55:00',\n",
       " '01/05/2014 13:00:00',\n",
       " '01/05/2014 13:05:00',\n",
       " '01/05/2014 13:10:00',\n",
       " '01/05/2014 13:15:00',\n",
       " '01/05/2014 13:20:00',\n",
       " '01/05/2014 13:25:00',\n",
       " '01/05/2014 13:30:00',\n",
       " '01/05/2014 13:35:00',\n",
       " '01/05/2014 13:40:00',\n",
       " '01/05/2014 13:45:00',\n",
       " '01/05/2014 13:50:00',\n",
       " '01/05/2014 13:55:00',\n",
       " '01/05/2014 14:00:00',\n",
       " '01/05/2014 14:05:00',\n",
       " '01/05/2014 14:10:00',\n",
       " '01/05/2014 14:15:00',\n",
       " '01/05/2014 14:20:00',\n",
       " '01/05/2014 14:25:00',\n",
       " '01/05/2014 14:30:00',\n",
       " '01/05/2014 14:35:00',\n",
       " '01/05/2014 14:40:00',\n",
       " '01/05/2014 14:45:00',\n",
       " '01/05/2014 14:50:00',\n",
       " '01/05/2014 14:55:00',\n",
       " '01/05/2014 15:00:00',\n",
       " '01/05/2014 15:05:00',\n",
       " '01/05/2014 15:10:00',\n",
       " '01/05/2014 15:15:00',\n",
       " '01/05/2014 15:20:00',\n",
       " '01/05/2014 15:25:00',\n",
       " '01/05/2014 15:30:00',\n",
       " '01/05/2014 15:35:00',\n",
       " '01/05/2014 15:40:00',\n",
       " '01/05/2014 15:45:00',\n",
       " '01/05/2014 15:50:00',\n",
       " '01/05/2014 15:55:00',\n",
       " '01/05/2014 16:00:00',\n",
       " '01/05/2014 16:05:00',\n",
       " '01/05/2014 16:10:00',\n",
       " '01/05/2014 16:15:00',\n",
       " '01/05/2014 16:20:00',\n",
       " '01/05/2014 16:25:00',\n",
       " '01/05/2014 16:30:00',\n",
       " '01/05/2014 16:35:00',\n",
       " '01/05/2014 16:40:00',\n",
       " '01/05/2014 16:45:00',\n",
       " '01/05/2014 16:50:00',\n",
       " '01/05/2014 16:55:00',\n",
       " '01/05/2014 17:00:00',\n",
       " '01/05/2014 17:05:00',\n",
       " '01/05/2014 17:10:00',\n",
       " '01/05/2014 17:15:00',\n",
       " '01/05/2014 17:20:00',\n",
       " '01/05/2014 17:25:00',\n",
       " '01/05/2014 17:30:00',\n",
       " '01/05/2014 17:35:00',\n",
       " '01/05/2014 17:40:00',\n",
       " '01/05/2014 17:45:00',\n",
       " '01/05/2014 17:50:00',\n",
       " '01/05/2014 17:55:00',\n",
       " '01/05/2014 18:00:00',\n",
       " '01/05/2014 18:05:00',\n",
       " '01/05/2014 18:10:00',\n",
       " '01/05/2014 18:15:00',\n",
       " '01/05/2014 18:20:00',\n",
       " '01/05/2014 18:25:00',\n",
       " '01/05/2014 18:30:00',\n",
       " '01/05/2014 18:35:00',\n",
       " '01/05/2014 18:40:00',\n",
       " '01/05/2014 18:45:00',\n",
       " '01/05/2014 18:50:00',\n",
       " '01/05/2014 18:55:00',\n",
       " '01/05/2014 19:00:00',\n",
       " '01/05/2014 19:05:00',\n",
       " '01/05/2014 19:10:00',\n",
       " '01/05/2014 19:15:00',\n",
       " '01/05/2014 19:20:00',\n",
       " '01/05/2014 19:25:00',\n",
       " '01/05/2014 19:30:00',\n",
       " '01/05/2014 19:35:00',\n",
       " '01/05/2014 19:40:00',\n",
       " '01/05/2014 19:45:00',\n",
       " '01/05/2014 19:50:00',\n",
       " '01/05/2014 19:55:00',\n",
       " '01/05/2014 20:00:00',\n",
       " '01/05/2014 20:05:00',\n",
       " '01/05/2014 20:10:00',\n",
       " '01/05/2014 20:15:00',\n",
       " '01/05/2014 20:20:00',\n",
       " '01/05/2014 20:25:00',\n",
       " '01/05/2014 20:30:00',\n",
       " '01/05/2014 20:35:00',\n",
       " '01/05/2014 20:40:00',\n",
       " '01/05/2014 20:45:00',\n",
       " '01/05/2014 20:50:00',\n",
       " '01/05/2014 20:55:00',\n",
       " '01/05/2014 21:00:00',\n",
       " '01/05/2014 21:05:00',\n",
       " '01/05/2014 21:10:00',\n",
       " '01/05/2014 21:15:00',\n",
       " '01/05/2014 21:20:00',\n",
       " '01/05/2014 21:25:00',\n",
       " '01/05/2014 21:30:00',\n",
       " '01/05/2014 21:35:00',\n",
       " '01/05/2014 21:40:00',\n",
       " '01/05/2014 21:45:00',\n",
       " '01/05/2014 21:50:00',\n",
       " '01/05/2014 21:55:00',\n",
       " '01/05/2014 22:00:00',\n",
       " '01/05/2014 22:05:00',\n",
       " '01/05/2014 22:10:00',\n",
       " '01/05/2014 22:15:00',\n",
       " '01/05/2014 22:20:00',\n",
       " '01/05/2014 22:25:00',\n",
       " '01/05/2014 22:30:00',\n",
       " '01/05/2014 22:35:00',\n",
       " '01/05/2014 22:40:00',\n",
       " '01/05/2014 22:45:00',\n",
       " '01/05/2014 22:50:00',\n",
       " '01/05/2014 22:55:00',\n",
       " '01/05/2014 23:00:00',\n",
       " '01/05/2014 23:05:00',\n",
       " '01/05/2014 23:10:00',\n",
       " '01/05/2014 23:15:00',\n",
       " '01/05/2014 23:20:00',\n",
       " '01/05/2014 23:25:00',\n",
       " '01/05/2014 23:30:00',\n",
       " '01/05/2014 23:35:00',\n",
       " '01/05/2014 23:40:00',\n",
       " '01/05/2014 23:45:00',\n",
       " '01/05/2014 23:50:00',\n",
       " '01/05/2014 23:55:00',\n",
       " '02/05/2014 00:00:00',\n",
       " '02/05/2014 00:05:00',\n",
       " '02/05/2014 00:10:00',\n",
       " '02/05/2014 00:15:00',\n",
       " '02/05/2014 00:20:00',\n",
       " '02/05/2014 00:25:00',\n",
       " '02/05/2014 00:30:00',\n",
       " '02/05/2014 00:35:00',\n",
       " '02/05/2014 00:40:00',\n",
       " '02/05/2014 00:45:00',\n",
       " '02/05/2014 00:50:00',\n",
       " '02/05/2014 00:55:00',\n",
       " '02/05/2014 01:00:00',\n",
       " '02/05/2014 01:05:00',\n",
       " '02/05/2014 01:10:00',\n",
       " '02/05/2014 01:15:00',\n",
       " '02/05/2014 01:20:00',\n",
       " '02/05/2014 01:25:00',\n",
       " '02/05/2014 01:30:00',\n",
       " '02/05/2014 01:35:00',\n",
       " '02/05/2014 01:40:00',\n",
       " '02/05/2014 01:45:00',\n",
       " '02/05/2014 01:50:00',\n",
       " '02/05/2014 01:55:00',\n",
       " '02/05/2014 02:00:00',\n",
       " '02/05/2014 02:05:00',\n",
       " '02/05/2014 02:10:00',\n",
       " '02/05/2014 02:15:00',\n",
       " '02/05/2014 02:20:00',\n",
       " '02/05/2014 02:25:00',\n",
       " '02/05/2014 02:30:00',\n",
       " '02/05/2014 02:35:00',\n",
       " '02/05/2014 02:40:00',\n",
       " '02/05/2014 02:45:00',\n",
       " '02/05/2014 02:50:00',\n",
       " '02/05/2014 02:55:00',\n",
       " '02/05/2014 03:00:00',\n",
       " '02/05/2014 03:05:00',\n",
       " '02/05/2014 03:10:00',\n",
       " '02/05/2014 03:15:00',\n",
       " '02/05/2014 03:20:00',\n",
       " '02/05/2014 03:25:00',\n",
       " '02/05/2014 03:30:00',\n",
       " '02/05/2014 03:35:00',\n",
       " '02/05/2014 03:40:00',\n",
       " '02/05/2014 03:45:00',\n",
       " '02/05/2014 03:50:00',\n",
       " '02/05/2014 03:55:00',\n",
       " '02/05/2014 04:00:00',\n",
       " '02/05/2014 04:05:00',\n",
       " '02/05/2014 04:10:00',\n",
       " '02/05/2014 04:15:00',\n",
       " '02/05/2014 04:20:00',\n",
       " '02/05/2014 04:25:00',\n",
       " '02/05/2014 04:30:00',\n",
       " '02/05/2014 04:35:00',\n",
       " '02/05/2014 04:40:00',\n",
       " '02/05/2014 04:45:00',\n",
       " '02/05/2014 04:50:00',\n",
       " '02/05/2014 04:55:00',\n",
       " '02/05/2014 05:00:00',\n",
       " '02/05/2014 05:05:00',\n",
       " '02/05/2014 05:10:00',\n",
       " '02/05/2014 05:15:00',\n",
       " '02/05/2014 05:20:00',\n",
       " '02/05/2014 05:25:00',\n",
       " '02/05/2014 05:30:00',\n",
       " '02/05/2014 05:35:00',\n",
       " '02/05/2014 05:40:00',\n",
       " '02/05/2014 05:45:00',\n",
       " '02/05/2014 05:50:00',\n",
       " '02/05/2014 05:55:00',\n",
       " '02/05/2014 06:00:00',\n",
       " '02/05/2014 06:05:00',\n",
       " '02/05/2014 06:10:00',\n",
       " '02/05/2014 06:15:00',\n",
       " '02/05/2014 06:20:00',\n",
       " '02/05/2014 06:25:00',\n",
       " '02/05/2014 06:30:00',\n",
       " '02/05/2014 06:35:00',\n",
       " '02/05/2014 06:40:00',\n",
       " '02/05/2014 06:45:00',\n",
       " '02/05/2014 06:50:00',\n",
       " '02/05/2014 06:55:00',\n",
       " '02/05/2014 07:00:00',\n",
       " '02/05/2014 07:05:00',\n",
       " '02/05/2014 07:10:00',\n",
       " '02/05/2014 07:15:00',\n",
       " '02/05/2014 07:20:00',\n",
       " '02/05/2014 07:25:00',\n",
       " '02/05/2014 07:30:00',\n",
       " '02/05/2014 07:35:00',\n",
       " '02/05/2014 07:40:00',\n",
       " '02/05/2014 07:45:00',\n",
       " '02/05/2014 07:50:00',\n",
       " '02/05/2014 07:55:00',\n",
       " '02/05/2014 08:00:00',\n",
       " '02/05/2014 08:05:00',\n",
       " '02/05/2014 08:10:00',\n",
       " '02/05/2014 08:15:00',\n",
       " '02/05/2014 08:20:00',\n",
       " '02/05/2014 08:25:00',\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thelist = result_df.loc[:,'DATETIME'].values.tolist()\n",
    "thelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153      241.1456604\n",
       "1154      235.0980988\n",
       "1155       263.460968\n",
       "1156      263.7768555\n",
       "1157      262.3990479\n",
       "1158       272.521637\n",
       "1159      260.5787354\n",
       "1160      258.8544312\n",
       "1161      237.4663544\n",
       "1162      246.8421478\n",
       "1163      263.1885681\n",
       "1164      270.0816956\n",
       "1165      256.6778564\n",
       "1166      275.1208191\n",
       "1167      244.5154724\n",
       "1168      263.1025696\n",
       "1169      270.1039429\n",
       "1170      258.8836365\n",
       "1171      272.8731689\n",
       "1172      254.2337799\n",
       "1173      276.7945557\n",
       "1174      262.9949951\n",
       "1175      239.6256256\n",
       "1176      249.6693878\n",
       "1177      240.0330963\n",
       "1178       242.628891\n",
       "1179      242.3943481\n",
       "1180      259.7544861\n",
       "1181      249.1735535\n",
       "1182      269.3968811\n",
       "             ...     \n",
       "138816       Shutdown\n",
       "138817       Shutdown\n",
       "138818       Shutdown\n",
       "138819       Shutdown\n",
       "138820       Shutdown\n",
       "152204       Shutdown\n",
       "152205       Shutdown\n",
       "152206       Shutdown\n",
       "159160       Shutdown\n",
       "215033       Shutdown\n",
       "238641            Bad\n",
       "238642            Bad\n",
       "238643            Bad\n",
       "238644            Bad\n",
       "266801            Bad\n",
       "266802            Bad\n",
       "266803            Bad\n",
       "266804            Bad\n",
       "266805            Bad\n",
       "266806            Bad\n",
       "266807            Bad\n",
       "266808            Bad\n",
       "271537            Bad\n",
       "271538            Bad\n",
       "271539            Bad\n",
       "271540            Bad\n",
       "271541            Bad\n",
       "271542            Bad\n",
       "271545            Bad\n",
       "271551            Bad\n",
       "Name: 905II259BI.PV, Length: 12520, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2[df2_2['DATETIME'].isin(result_df.loc[:,'DATETIME'].values.tolist())][Sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSVFile = CSVFileList[0]\n",
    "CSVFileWithPath = CSVPath1 + \"/\" + CSVFileList[0]\n",
    "\n",
    "csvFileSizeGB = GetFileSize(CSVFileWithPath)\n",
    "\n",
    "if csvFileSizeGB > 1:\n",
    "    StringListForAllSensors = SplitCSVFile_GetStrings(CSVFileWithPath, CSVFile)\n",
    "    print ('These are all the strings found in the file: ' + str(StringListForAllSensors))\n",
    "else:\n",
    "    \n",
    "    df2 = LoadCSV(CSVFileWithPath, CSVFile)\n",
    "    \n",
    "    # Rename date and time column\n",
    "    print ('Renaming date and time column')\n",
    "    RenameColumn(df2)\n",
    "    # Apply Date and time format to dataframe\n",
    "    print ('Applying date and time format')\n",
    "    ApplyDateFormat(df2)\n",
    "    \n",
    "    # Apply Index and create two dataframes\n",
    "    df2_1, df2_2 = SetIndex(df2)\n",
    "    \n",
    "    print ('Extracting strings from csv file')\n",
    "    StringListForAllSensors = ExtractStrings(df2_1, df2_2)\n",
    "    \n",
    "    print ('These are all the strings found in the csv file: ' + str(StringListForAllSensors))\n",
    "\n",
    "# Convert all strings to a Dictionary\n",
    "StringListDict = {}.fromkeys(StringListForAllSensors, 'null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CSVFile = CSVFileList[0]\n",
    "# CSVFileWithPath = CSVPath1 + \"/\" + CSVFileList[0]\n",
    "\n",
    "# StringListForAllSensors = SplitCSVFile_GetStrings(CSVFileWithPath, CSVFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run following line to see the list of Strings\n",
    "## Copy the result and paste it in the following line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StringListDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now we can replace string with null or a number\n",
    "## I have assigned null to all strings by default all strings are replaced with null. If the strings need to be replaced with a number please replace the null with your desired number\n",
    "###Example\n",
    "###{'String 1': 'null',\n",
    "    'String 2': 1,\n",
    "    'String 3': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The replace code is still Work in Progress for files bigger than 1 GB\n",
    "#### What to do\n",
    "##### 1. Since the code does not load the whole CSV but splits it. The code needs to open each splitted file and do the replace\n",
    "##### 2. Once text is replaced the CSV file will be updated and load the next\n",
    "##### 3. Once all csv file are processed We need to convert them to Previse Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing known test to null\n",
    "df2_2.replace(\n",
    "{'Bad': 0,\n",
    " 'CLOSE': 0,\n",
    " 'Comm Fail': 'null',\n",
    " 'Configure': 'null',\n",
    " 'Error': 'null',\n",
    " \"Exception of type 'System.OutOfMemoryException' was thrown.\": 'null',\n",
    " 'Failed': 'null',\n",
    " 'I/O Timeout': 'null',\n",
    " 'Intf Shut': 'null',\n",
    " 'MEM_ERR': 'null',\n",
    " 'ON': 1,\n",
    " 'OPEN': 1,\n",
    " 'Off': 0,\n",
    " 'RUN': 1,\n",
    " 'STOP': 0,\n",
    " 'Scan Off': 'null',\n",
    " 'Scan Timeout': 'null'}\n",
    ", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now we convert the data to linear format Previse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------\n",
    "## The format and Split will be done in the same step (this is to be done for files bigger than 1GB)\n",
    "### The code will loop thru each chunk and will Format to Previse then will Split the file\n",
    "### Each file will be a sensor\n",
    "### If the sensor csv file has more than 1MM rows the code will split that file also\n",
    "## -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FormatToPrevise code is still Work in Progress for files bigger than 1 GB\n",
    "### What to do\n",
    "#### 1. Since the code does not load the whole CSV but splits it. The code needs to open each splitted file and do the Formatting\n",
    "#### 2. The code will loop thru each Splitted CSV file and format each one of them\n",
    "#### 3. Once formatted the code will split the file into 1MM rows per CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdf = FormatToPrevise(df2_1,df2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run following line to see the TOP 25 rows for the new Previse Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdf.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Here we split the CSV data by file and each file will contain 1 million rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SplitPreviseFormatCSVFile code is still Work in Progress for files bigger than 1 GB\n",
    "### What to do\n",
    "\n",
    "### Improvement\n",
    "#### 1. I will update the code to create a CSV file per Sensor and if the sensor has more than 1MM rows it will splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SplitPreviseFormatCSVFile(mdf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
